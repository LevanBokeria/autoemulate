{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Simulate some data and fit emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from autoemulate.experimental.simulations.projectile import ProjectileMultioutput\n",
    "from autoemulate.experimental.emulators.gaussian_process.exact import (\n",
    "    GaussianProcessExact,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running simulations: 100%|██████████| 10/10 [00:00<00:00, 547.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully completed 10/10 simulations (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sim = ProjectileMultioutput()\n",
    "x = sim.sample_inputs(10)\n",
    "y = sim.forward_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0018, 1.5183], dtype=torch.float64),\n",
       " tensor([52476.1038,   599.9588], dtype=torch.float64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check range of training outputs\n",
    "torch.min(y, dim=0).values, torch.max(y, dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GaussianProcessExact(x, y)\n",
    "gp.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple HMC example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.experimental.calibration.hmc import HMCCalibrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with an observation inside the training range, we should be able to recover the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the ranges, we can actually just them to the same thing\n",
    "observations = {name: 100 for name in sim.output_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc = HMCCalibrator(gp, sim.parameters_range, observations, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 110/110 [00:00, 348.17it/s, step size=4.36e-02, acc. prob=0.003]\n"
     ]
    }
   ],
   "source": [
    "mcmc = hmc.run_mcmc(warmup_steps=10, num_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned Pyro MCMC object has methods for accessing the generated samples (`mcmc.get_samples()`) or, as shown below, to get just their summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "         c     -1.29      0.04     -1.25     -1.34     -1.25      2.64      6.99\n",
      "        v0    652.24      0.13    652.30    652.06    652.40      5.86      1.25\n",
      "\n",
      "Number of divergences: 100\n"
     ]
    }
   ],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combining this with sensitivity analysis and history matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HMCCalibrator` object has an option to provide a list of parameters to calibrate. These can be the result of `SensitivityAnalysis`, or just a list provided by the user.\n",
    "\n",
    "Similarly, the user provides parameter ranges from which to sample or set the parameter values. This can be simply the range of the simulator or one can use `HistoryMatching` to reduce the parameter range and pass that to the `HMCCalibrator` instead. \n",
    "\n",
    "Below we demonstrate how to do both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.experimental.sensitivity_analysis import SensitivityAnalysis\n",
    "from autoemulate.experimental.calibration.history_matching import HistoryMatching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run sensitivity analysis and get top N parameters (here we just get the top 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjersakova/Documents/Projects/autoemulate/.venv/lib/python3.12/site-packages/SALib/util/__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n",
      "/Users/rjersakova/Documents/Projects/autoemulate/.venv/lib/python3.12/site-packages/SALib/util/__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    }
   ],
   "source": [
    "problem = {\n",
    "        \"num_vars\": 2,\n",
    "        \"names\": [\"c\", \"v0\"],\n",
    "        \"bounds\": [(-5.0, 1.0), (0.0, 1000.0)],\n",
    "    }\n",
    "sa = SensitivityAnalysis(gp, problem=problem)\n",
    "df = sa.run(\"sobol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v0']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_param = sa.top_n_params(df, 1)\n",
    "top_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run history matching and generate new parameter bounds from NROY samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/kdwy1bhj3h728lr5xdj19yd40000gr/T/ipykernel_69876/680583242.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = gp.predict(torch.tensor(x_new, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "# start with some GP predictions\n",
    "x_new = sim.sample_inputs(10)\n",
    "output = gp.predict(torch.tensor(x_new, dtype=torch.float32))\n",
    "pred_means, pred_vars = (\n",
    "    output.mean.float().detach(),\n",
    "    output.variance.float().detach(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate NROY samples\n",
    "hm = HistoryMatching(\n",
    "    observations={\"v0\": (10, 5), \"c\": (10 ,5)},\n",
    "    threshold=3.0\n",
    ")\n",
    "implausability = hm.calculate_implausibility(pred_means, pred_vars)\n",
    "nroy_samples = hm.get_nroy(implausability, x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v0': [tensor(-5.0463), tensor(1.1488)],\n",
       " 'c': [tensor(-32.9765), tensor(899.2466)]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get new param bounds\n",
    "nroy_param_range = hm.generate_param_bounds(nroy_samples, param_names = [\"v0\", \"c\"])\n",
    "nroy_param_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pass results to the HMCCalibrator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc = HMCCalibrator(\n",
    "    gp, \n",
    "    nroy_param_range, \n",
    "    observations, \n",
    "    1.0,\n",
    "    top_param\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1500/1500 [00:04, 318.37it/s, step size=1.07e+00, acc. prob=0.882]\n"
     ]
    }
   ],
   "source": [
    "mcmc = hmc.run_mcmc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        v0     -1.96      1.76     -1.82     -5.01      0.38    409.20      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "mcmc.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
