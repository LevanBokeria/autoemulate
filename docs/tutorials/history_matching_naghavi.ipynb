{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo for a complete autoemulate pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you have a simulation , put your simulator in a simulator object \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ao.r': (120.0, 360.0),\n",
       " 'ao.c': (0.15, 0.44999999999999996),\n",
       " 'art.r': (562.5, 1687.5),\n",
       " 'art.c': (1.5, 4.5),\n",
       " 'ven.r': (4.5, 13.5),\n",
       " 'ven.c': (66.65, 199.95000000000002),\n",
       " 'av.r': (3.0, 9.0),\n",
       " 'mv.r': (2.05, 6.1499999999999995),\n",
       " 'la.E_pas': (0.22, 0.66),\n",
       " 'la.E_act': (0.225, 0.675),\n",
       " 'la.v_ref': (5.0, 15.0),\n",
       " 'la.k_pas': (0.01665, 0.07500000000000001),\n",
       " 'lv.E_pas': (0.5, 1.5),\n",
       " 'lv.E_act': (1.5, 4.5),\n",
       " 'lv.v_ref': (5.0, 15.0),\n",
       " 'lv.k_pas': (0.00999, 0.045)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autoemulate.simulations.naghavi_cardiac_ModularCirc import extract_parameter_ranges\n",
    "# Usage example:\n",
    "parameters_range = extract_parameter_ranges('/Users/mfamili/work/ModularCirc/Tutorials/Tutorial_03/Parameters_01.json')\n",
    "parameters_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 16 Number of samples from each parameter: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ao.r</th>\n",
       "      <th>ao.c</th>\n",
       "      <th>art.r</th>\n",
       "      <th>art.c</th>\n",
       "      <th>ven.r</th>\n",
       "      <th>ven.c</th>\n",
       "      <th>av.r</th>\n",
       "      <th>mv.r</th>\n",
       "      <th>la.E_pas</th>\n",
       "      <th>la.E_act</th>\n",
       "      <th>la.v_ref</th>\n",
       "      <th>la.k_pas</th>\n",
       "      <th>lv.E_pas</th>\n",
       "      <th>lv.E_act</th>\n",
       "      <th>lv.v_ref</th>\n",
       "      <th>lv.k_pas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334.247200</td>\n",
       "      <td>0.298126</td>\n",
       "      <td>1350.339838</td>\n",
       "      <td>1.878151</td>\n",
       "      <td>12.089577</td>\n",
       "      <td>110.041047</td>\n",
       "      <td>8.570339</td>\n",
       "      <td>4.966271</td>\n",
       "      <td>0.381802</td>\n",
       "      <td>0.581709</td>\n",
       "      <td>5.187959</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>1.090765</td>\n",
       "      <td>2.117194</td>\n",
       "      <td>12.542671</td>\n",
       "      <td>0.015339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317.081500</td>\n",
       "      <td>0.392056</td>\n",
       "      <td>1385.423091</td>\n",
       "      <td>2.726083</td>\n",
       "      <td>8.005873</td>\n",
       "      <td>186.744788</td>\n",
       "      <td>6.715292</td>\n",
       "      <td>4.115116</td>\n",
       "      <td>0.524411</td>\n",
       "      <td>0.587504</td>\n",
       "      <td>11.651372</td>\n",
       "      <td>0.042936</td>\n",
       "      <td>1.280037</td>\n",
       "      <td>3.137457</td>\n",
       "      <td>13.798822</td>\n",
       "      <td>0.010986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188.924960</td>\n",
       "      <td>0.231354</td>\n",
       "      <td>1517.702080</td>\n",
       "      <td>3.955581</td>\n",
       "      <td>5.599686</td>\n",
       "      <td>119.413594</td>\n",
       "      <td>4.013578</td>\n",
       "      <td>5.303890</td>\n",
       "      <td>0.263311</td>\n",
       "      <td>0.475333</td>\n",
       "      <td>5.095720</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>1.379846</td>\n",
       "      <td>1.776955</td>\n",
       "      <td>13.903043</td>\n",
       "      <td>0.033848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343.042923</td>\n",
       "      <td>0.399963</td>\n",
       "      <td>1284.803060</td>\n",
       "      <td>3.559930</td>\n",
       "      <td>11.055576</td>\n",
       "      <td>151.606996</td>\n",
       "      <td>3.329687</td>\n",
       "      <td>3.337612</td>\n",
       "      <td>0.243984</td>\n",
       "      <td>0.465899</td>\n",
       "      <td>12.162585</td>\n",
       "      <td>0.058591</td>\n",
       "      <td>0.783127</td>\n",
       "      <td>2.911347</td>\n",
       "      <td>14.962053</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248.324563</td>\n",
       "      <td>0.165977</td>\n",
       "      <td>919.434490</td>\n",
       "      <td>2.253556</td>\n",
       "      <td>10.583195</td>\n",
       "      <td>101.906029</td>\n",
       "      <td>8.477522</td>\n",
       "      <td>3.946127</td>\n",
       "      <td>0.226862</td>\n",
       "      <td>0.321755</td>\n",
       "      <td>8.056464</td>\n",
       "      <td>0.020150</td>\n",
       "      <td>0.638783</td>\n",
       "      <td>3.388206</td>\n",
       "      <td>12.176559</td>\n",
       "      <td>0.030031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ao.r      ao.c        art.r     art.c      ven.r       ven.c  \\\n",
       "0  334.247200  0.298126  1350.339838  1.878151  12.089577  110.041047   \n",
       "1  317.081500  0.392056  1385.423091  2.726083   8.005873  186.744788   \n",
       "2  188.924960  0.231354  1517.702080  3.955581   5.599686  119.413594   \n",
       "3  343.042923  0.399963  1284.803060  3.559930  11.055576  151.606996   \n",
       "4  248.324563  0.165977   919.434490  2.253556  10.583195  101.906029   \n",
       "\n",
       "       av.r      mv.r  la.E_pas  la.E_act   la.v_ref  la.k_pas  lv.E_pas  \\\n",
       "0  8.570339  4.966271  0.381802  0.581709   5.187959  0.034208  1.090765   \n",
       "1  6.715292  4.115116  0.524411  0.587504  11.651372  0.042936  1.280037   \n",
       "2  4.013578  5.303890  0.263311  0.475333   5.095720  0.069382  1.379846   \n",
       "3  3.329687  3.337612  0.243984  0.465899  12.162585  0.058591  0.783127   \n",
       "4  8.477522  3.946127  0.226862  0.321755   8.056464  0.020150  0.638783   \n",
       "\n",
       "   lv.E_act   lv.v_ref  lv.k_pas  \n",
       "0  2.117194  12.542671  0.015339  \n",
       "1  3.137457  13.798822  0.010986  \n",
       "2  1.776955  13.903043  0.033848  \n",
       "3  2.911347  14.962053  0.022136  \n",
       "4  3.388206  12.176559  0.030031  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autoemulate.experimental_design import LatinHypercube\n",
    "\n",
    "\n",
    "# Generate Latin Hypercube samples\n",
    "N_samples = 60\n",
    "lhd = LatinHypercube(list(parameters_range.values()))\n",
    "sample_array = lhd.sample(N_samples)\n",
    "sample_df = pd.DataFrame(sample_array, columns=parameters_range.keys())\n",
    "\n",
    "print(\"Number of parameters:\", sample_df.shape[1], \"Number of samples from each parameter:\", sample_df.shape[0])\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965e46dbbe6e41e5a9c651c32c634076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running simulations:   0%|          | 0/60 [00:00<?, ?sample/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully completed 60/60 simulations (100.0%)\n"
     ]
    }
   ],
   "source": [
    "from autoemulate.simulations.naghavi_cardiac_ModularCirc import NaghaviSimulator\n",
    "\n",
    "# Initialize the simulator\n",
    "simulator = NaghaviSimulator(n_cycles=1000, dt=0.001)\n",
    "\n",
    "# Run batch simulations with the samples generated in Cell 1\n",
    "results = simulator.run_batch_simulations(sample_df)\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ao.r</th>\n",
       "      <th>ao.c</th>\n",
       "      <th>art.r</th>\n",
       "      <th>art.c</th>\n",
       "      <th>ven.r</th>\n",
       "      <th>ven.c</th>\n",
       "      <th>av.r</th>\n",
       "      <th>mv.r</th>\n",
       "      <th>la.E_pas</th>\n",
       "      <th>la.E_act</th>\n",
       "      <th>la.v_ref</th>\n",
       "      <th>la.k_pas</th>\n",
       "      <th>lv.E_pas</th>\n",
       "      <th>lv.E_act</th>\n",
       "      <th>lv.v_ref</th>\n",
       "      <th>lv.k_pas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>240.144601</td>\n",
       "      <td>0.300008</td>\n",
       "      <td>1124.802745</td>\n",
       "      <td>2.998736</td>\n",
       "      <td>8.998322</td>\n",
       "      <td>133.353206</td>\n",
       "      <td>5.997795</td>\n",
       "      <td>4.098871</td>\n",
       "      <td>0.440425</td>\n",
       "      <td>0.450209</td>\n",
       "      <td>9.995860</td>\n",
       "      <td>0.045818</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>3.001080</td>\n",
       "      <td>10.001049</td>\n",
       "      <td>0.027489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>69.864370</td>\n",
       "      <td>0.087405</td>\n",
       "      <td>328.080066</td>\n",
       "      <td>0.872015</td>\n",
       "      <td>2.625963</td>\n",
       "      <td>38.766292</td>\n",
       "      <td>1.753916</td>\n",
       "      <td>1.189523</td>\n",
       "      <td>0.128150</td>\n",
       "      <td>0.130899</td>\n",
       "      <td>2.927277</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>0.290426</td>\n",
       "      <td>0.875289</td>\n",
       "      <td>2.916978</td>\n",
       "      <td>0.010171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>120.851584</td>\n",
       "      <td>0.152636</td>\n",
       "      <td>578.657920</td>\n",
       "      <td>1.519576</td>\n",
       "      <td>4.542914</td>\n",
       "      <td>68.797237</td>\n",
       "      <td>3.097075</td>\n",
       "      <td>2.115809</td>\n",
       "      <td>0.226862</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>5.095720</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.515731</td>\n",
       "      <td>1.549122</td>\n",
       "      <td>5.049720</td>\n",
       "      <td>0.010389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>182.503622</td>\n",
       "      <td>0.224668</td>\n",
       "      <td>853.064929</td>\n",
       "      <td>2.244686</td>\n",
       "      <td>6.714384</td>\n",
       "      <td>101.286102</td>\n",
       "      <td>4.514276</td>\n",
       "      <td>3.113774</td>\n",
       "      <td>0.329338</td>\n",
       "      <td>0.340839</td>\n",
       "      <td>7.555261</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>0.748673</td>\n",
       "      <td>2.256165</td>\n",
       "      <td>7.576440</td>\n",
       "      <td>0.018979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.558239</td>\n",
       "      <td>0.300678</td>\n",
       "      <td>1121.138657</td>\n",
       "      <td>2.999078</td>\n",
       "      <td>8.983392</td>\n",
       "      <td>133.480469</td>\n",
       "      <td>6.041953</td>\n",
       "      <td>4.076417</td>\n",
       "      <td>0.439533</td>\n",
       "      <td>0.448313</td>\n",
       "      <td>9.973850</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.994735</td>\n",
       "      <td>3.001396</td>\n",
       "      <td>10.018977</td>\n",
       "      <td>0.027471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299.482780</td>\n",
       "      <td>0.373220</td>\n",
       "      <td>1407.853868</td>\n",
       "      <td>3.736246</td>\n",
       "      <td>11.242930</td>\n",
       "      <td>166.890197</td>\n",
       "      <td>7.496350</td>\n",
       "      <td>5.088525</td>\n",
       "      <td>0.550731</td>\n",
       "      <td>0.561519</td>\n",
       "      <td>12.442595</td>\n",
       "      <td>0.060322</td>\n",
       "      <td>1.252377</td>\n",
       "      <td>3.741546</td>\n",
       "      <td>12.413601</td>\n",
       "      <td>0.036154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>358.412888</td>\n",
       "      <td>0.446948</td>\n",
       "      <td>1675.143810</td>\n",
       "      <td>4.477666</td>\n",
       "      <td>13.386768</td>\n",
       "      <td>197.872961</td>\n",
       "      <td>8.929164</td>\n",
       "      <td>6.109173</td>\n",
       "      <td>0.656608</td>\n",
       "      <td>0.671993</td>\n",
       "      <td>14.999613</td>\n",
       "      <td>0.074161</td>\n",
       "      <td>1.493644</td>\n",
       "      <td>4.481787</td>\n",
       "      <td>14.962053</td>\n",
       "      <td>0.044979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ao.r       ao.c        art.r      art.c      ven.r       ven.c  \\\n",
       "count   60.000000  60.000000    60.000000  60.000000  60.000000   60.000000   \n",
       "mean   240.144601   0.300008  1124.802745   2.998736   8.998322  133.353206   \n",
       "std     69.864370   0.087405   328.080066   0.872015   2.625963   38.766292   \n",
       "min    120.851584   0.152636   578.657920   1.519576   4.542914   68.797237   \n",
       "25%    182.503622   0.224668   853.064929   2.244686   6.714384  101.286102   \n",
       "50%    240.558239   0.300678  1121.138657   2.999078   8.983392  133.480469   \n",
       "75%    299.482780   0.373220  1407.853868   3.736246  11.242930  166.890197   \n",
       "max    358.412888   0.446948  1675.143810   4.477666  13.386768  197.872961   \n",
       "\n",
       "            av.r       mv.r   la.E_pas   la.E_act   la.v_ref   la.k_pas  \\\n",
       "count  60.000000  60.000000  60.000000  60.000000  60.000000  60.000000   \n",
       "mean    5.997795   4.098871   0.440425   0.450209   9.995860   0.045818   \n",
       "std     1.753916   1.189523   0.128150   0.130899   2.927277   0.016978   \n",
       "min     3.097075   2.115809   0.226862   0.226365   5.095720   0.017442   \n",
       "25%     4.514276   3.113774   0.329338   0.340839   7.555261   0.031070   \n",
       "50%     6.041953   4.076417   0.439533   0.448313   9.973850   0.045784   \n",
       "75%     7.496350   5.088525   0.550731   0.561519  12.442595   0.060322   \n",
       "max     8.929164   6.109173   0.656608   0.671993  14.999613   0.074161   \n",
       "\n",
       "        lv.E_pas   lv.E_act   lv.v_ref   lv.k_pas  \n",
       "count  60.000000  60.000000  60.000000  60.000000  \n",
       "mean    0.999738   3.001080  10.001049   0.027489  \n",
       "std     0.290426   0.875289   2.916978   0.010171  \n",
       "min     0.515731   1.549122   5.049720   0.010389  \n",
       "25%     0.748673   2.256165   7.576440   0.018979  \n",
       "50%     0.994735   3.001396  10.018977   0.027471  \n",
       "75%     1.252377   3.741546  12.413601   0.036154  \n",
       "max     1.493644   4.481787  14.962053   0.044979  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test your simulator with our test function to make sure it ios compatible wih AutoEmulate pipelien "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a test for the simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ao.r</th>\n",
       "      <th>ao.c</th>\n",
       "      <th>art.r</th>\n",
       "      <th>art.c</th>\n",
       "      <th>ven.r</th>\n",
       "      <th>ven.c</th>\n",
       "      <th>av.r</th>\n",
       "      <th>mv.r</th>\n",
       "      <th>la.E_pas</th>\n",
       "      <th>la.E_act</th>\n",
       "      <th>...</th>\n",
       "      <th>la.P_o</th>\n",
       "      <th>la.Q_i</th>\n",
       "      <th>la.Q_o</th>\n",
       "      <th>la.V</th>\n",
       "      <th>lv.P</th>\n",
       "      <th>lv.P_i</th>\n",
       "      <th>lv.P_o</th>\n",
       "      <th>lv.Q_i</th>\n",
       "      <th>lv.Q_o</th>\n",
       "      <th>lv.V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334.247200</td>\n",
       "      <td>0.298126</td>\n",
       "      <td>1350.339838</td>\n",
       "      <td>1.878151</td>\n",
       "      <td>12.089577</td>\n",
       "      <td>110.041047</td>\n",
       "      <td>8.570339</td>\n",
       "      <td>4.966271</td>\n",
       "      <td>0.381802</td>\n",
       "      <td>0.581709</td>\n",
       "      <td>...</td>\n",
       "      <td>[40.04067347593265, 40.036089392716015, 40.031...</td>\n",
       "      <td>[-2.575050406038219, -2.574669242288889, -2.57...</td>\n",
       "      <td>[7.388980352594501, 7.387956074297883, 7.38693...</td>\n",
       "      <td>[93.6, 93.59003737462166, 93.58007613600397, 9...</td>\n",
       "      <td>[3.344995295156757, 3.3454980554485165, 3.3460...</td>\n",
       "      <td>[3.344995295156757, 3.3454980554485165, 3.3460...</td>\n",
       "      <td>[3.344995295156757, 3.3454980554485165, 3.3460...</td>\n",
       "      <td>[7.388980352594501, 7.387956074297883, 7.38693...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[104.0, 104.00738795611932, 104.0147749015686,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317.081500</td>\n",
       "      <td>0.392056</td>\n",
       "      <td>1385.423091</td>\n",
       "      <td>2.726083</td>\n",
       "      <td>8.005873</td>\n",
       "      <td>186.744788</td>\n",
       "      <td>6.715292</td>\n",
       "      <td>4.115116</td>\n",
       "      <td>0.524411</td>\n",
       "      <td>0.587504</td>\n",
       "      <td>...</td>\n",
       "      <td>[40.118114617784876, 40.10982010907997, 40.101...</td>\n",
       "      <td>[-4.355323719223735, -4.354284722311319, -4.35...</td>\n",
       "      <td>[9.222103049352121, 9.220002533539748, 9.21790...</td>\n",
       "      <td>[93.6, 93.5864257115181, 93.57285444090711, 93...</td>\n",
       "      <td>[2.1680888544500263, 2.168438212417316, 2.1687...</td>\n",
       "      <td>[2.1680888544500263, 2.168438212417316, 2.1687...</td>\n",
       "      <td>[2.1680888544500263, 2.168438212417316, 2.1687...</td>\n",
       "      <td>[9.222103049352121, 9.220002533539748, 9.21790...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[104.00000000000001, 104.00922000335386, 104.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188.924960</td>\n",
       "      <td>0.231354</td>\n",
       "      <td>1517.702080</td>\n",
       "      <td>3.955581</td>\n",
       "      <td>5.599686</td>\n",
       "      <td>119.413594</td>\n",
       "      <td>4.013578</td>\n",
       "      <td>5.303890</td>\n",
       "      <td>0.263311</td>\n",
       "      <td>0.475333</td>\n",
       "      <td>...</td>\n",
       "      <td>[62.78053779067132, 62.738189377720246, 62.695...</td>\n",
       "      <td>[-9.745263184387019, -9.737685941583159, -9.73...</td>\n",
       "      <td>[6.605536176122244, 6.59632537653942, 6.587127...</td>\n",
       "      <td>[93.6, 93.58366551874924, 93.56734358961644, 9...</td>\n",
       "      <td>[27.745500516117207, 27.752005170972975, 27.75...</td>\n",
       "      <td>[27.745500516117207, 27.752005170972975, 27.75...</td>\n",
       "      <td>[27.745500516117207, 27.752005170972975, 27.75...</td>\n",
       "      <td>[6.605536176122244, 6.59632537653942, 6.587127...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[104.0, 104.00659658321501, 104.01318627931053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343.042923</td>\n",
       "      <td>0.399963</td>\n",
       "      <td>1284.803060</td>\n",
       "      <td>3.559930</td>\n",
       "      <td>11.055576</td>\n",
       "      <td>151.606996</td>\n",
       "      <td>3.329687</td>\n",
       "      <td>3.337612</td>\n",
       "      <td>0.243984</td>\n",
       "      <td>0.465899</td>\n",
       "      <td>...</td>\n",
       "      <td>[35.51295758059091, 35.50380144202827, 35.4946...</td>\n",
       "      <td>[-2.627293086584822, -2.626463305605376, -2.62...</td>\n",
       "      <td>[9.190775239980267, 9.18768932610401, 9.184605...</td>\n",
       "      <td>[93.6, 93.5881858438275, 93.57637537596842, 93...</td>\n",
       "      <td>[4.837712590934286, 4.83885603665039, 4.839999...</td>\n",
       "      <td>[4.837712590934286, 4.83885603665039, 4.839999...</td>\n",
       "      <td>[4.837712590934286, 4.83885603665039, 4.839999...</td>\n",
       "      <td>[9.190775239980267, 9.18768932610401, 9.184605...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[104.0, 104.00918769211658, 104.01837247747224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248.324563</td>\n",
       "      <td>0.165977</td>\n",
       "      <td>919.434490</td>\n",
       "      <td>2.253556</td>\n",
       "      <td>10.583195</td>\n",
       "      <td>101.906029</td>\n",
       "      <td>8.477522</td>\n",
       "      <td>3.946127</td>\n",
       "      <td>0.226862</td>\n",
       "      <td>0.321755</td>\n",
       "      <td>...</td>\n",
       "      <td>[20.66270105780273, 20.66199100804784, 20.6612...</td>\n",
       "      <td>[-1.0433590819294625, -1.043290946159945, -1.0...</td>\n",
       "      <td>[2.8466474216865785, 2.846249363170714, 2.8458...</td>\n",
       "      <td>[93.6, 93.5961104596853, 93.59222138239498, 93...</td>\n",
       "      <td>[9.429469391344384, 9.430330130964895, 9.43119...</td>\n",
       "      <td>[9.429469391344384, 9.430330130964895, 9.43119...</td>\n",
       "      <td>[9.429469391344384, 9.430330130964895, 9.43119...</td>\n",
       "      <td>[2.8466474216865785, 2.846249363170714, 2.8458...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[103.99999999999999, 104.00284624936774, 104.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ao.r      ao.c        art.r     art.c      ven.r       ven.c  \\\n",
       "0  334.247200  0.298126  1350.339838  1.878151  12.089577  110.041047   \n",
       "1  317.081500  0.392056  1385.423091  2.726083   8.005873  186.744788   \n",
       "2  188.924960  0.231354  1517.702080  3.955581   5.599686  119.413594   \n",
       "3  343.042923  0.399963  1284.803060  3.559930  11.055576  151.606996   \n",
       "4  248.324563  0.165977   919.434490  2.253556  10.583195  101.906029   \n",
       "\n",
       "       av.r      mv.r  la.E_pas  la.E_act  ...  \\\n",
       "0  8.570339  4.966271  0.381802  0.581709  ...   \n",
       "1  6.715292  4.115116  0.524411  0.587504  ...   \n",
       "2  4.013578  5.303890  0.263311  0.475333  ...   \n",
       "3  3.329687  3.337612  0.243984  0.465899  ...   \n",
       "4  8.477522  3.946127  0.226862  0.321755  ...   \n",
       "\n",
       "                                              la.P_o  \\\n",
       "0  [40.04067347593265, 40.036089392716015, 40.031...   \n",
       "1  [40.118114617784876, 40.10982010907997, 40.101...   \n",
       "2  [62.78053779067132, 62.738189377720246, 62.695...   \n",
       "3  [35.51295758059091, 35.50380144202827, 35.4946...   \n",
       "4  [20.66270105780273, 20.66199100804784, 20.6612...   \n",
       "\n",
       "                                              la.Q_i  \\\n",
       "0  [-2.575050406038219, -2.574669242288889, -2.57...   \n",
       "1  [-4.355323719223735, -4.354284722311319, -4.35...   \n",
       "2  [-9.745263184387019, -9.737685941583159, -9.73...   \n",
       "3  [-2.627293086584822, -2.626463305605376, -2.62...   \n",
       "4  [-1.0433590819294625, -1.043290946159945, -1.0...   \n",
       "\n",
       "                                              la.Q_o  \\\n",
       "0  [7.388980352594501, 7.387956074297883, 7.38693...   \n",
       "1  [9.222103049352121, 9.220002533539748, 9.21790...   \n",
       "2  [6.605536176122244, 6.59632537653942, 6.587127...   \n",
       "3  [9.190775239980267, 9.18768932610401, 9.184605...   \n",
       "4  [2.8466474216865785, 2.846249363170714, 2.8458...   \n",
       "\n",
       "                                                la.V  \\\n",
       "0  [93.6, 93.59003737462166, 93.58007613600397, 9...   \n",
       "1  [93.6, 93.5864257115181, 93.57285444090711, 93...   \n",
       "2  [93.6, 93.58366551874924, 93.56734358961644, 9...   \n",
       "3  [93.6, 93.5881858438275, 93.57637537596842, 93...   \n",
       "4  [93.6, 93.5961104596853, 93.59222138239498, 93...   \n",
       "\n",
       "                                                lv.P  \\\n",
       "0  [3.344995295156757, 3.3454980554485165, 3.3460...   \n",
       "1  [2.1680888544500263, 2.168438212417316, 2.1687...   \n",
       "2  [27.745500516117207, 27.752005170972975, 27.75...   \n",
       "3  [4.837712590934286, 4.83885603665039, 4.839999...   \n",
       "4  [9.429469391344384, 9.430330130964895, 9.43119...   \n",
       "\n",
       "                                              lv.P_i  \\\n",
       "0  [3.344995295156757, 3.3454980554485165, 3.3460...   \n",
       "1  [2.1680888544500263, 2.168438212417316, 2.1687...   \n",
       "2  [27.745500516117207, 27.752005170972975, 27.75...   \n",
       "3  [4.837712590934286, 4.83885603665039, 4.839999...   \n",
       "4  [9.429469391344384, 9.430330130964895, 9.43119...   \n",
       "\n",
       "                                              lv.P_o  \\\n",
       "0  [3.344995295156757, 3.3454980554485165, 3.3460...   \n",
       "1  [2.1680888544500263, 2.168438212417316, 2.1687...   \n",
       "2  [27.745500516117207, 27.752005170972975, 27.75...   \n",
       "3  [4.837712590934286, 4.83885603665039, 4.839999...   \n",
       "4  [9.429469391344384, 9.430330130964895, 9.43119...   \n",
       "\n",
       "                                              lv.Q_i  \\\n",
       "0  [7.388980352594501, 7.387956074297883, 7.38693...   \n",
       "1  [9.222103049352121, 9.220002533539748, 9.21790...   \n",
       "2  [6.605536176122244, 6.59632537653942, 6.587127...   \n",
       "3  [9.190775239980267, 9.18768932610401, 9.184605...   \n",
       "4  [2.8466474216865785, 2.846249363170714, 2.8458...   \n",
       "\n",
       "                                              lv.Q_o  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                lv.V  \n",
       "0  [104.0, 104.00738795611932, 104.0147749015686,...  \n",
       "1  [104.00000000000001, 104.00922000335386, 104.0...  \n",
       "2  [104.0, 104.00659658321501, 104.01318627931053...  \n",
       "3  [104.0, 104.00918769211658, 104.01837247747224...  \n",
       "4  [103.99999999999999, 104.00284624936774, 104.0...  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting wave 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean   10.338103   9.105457   4.648469       85.233255  9.853282e+01   \n",
      "std     5.850657   5.166678   2.867269       84.201274  9.246473e-07   \n",
      "min     0.372654   0.486470   0.014313       27.490180  9.853282e+01   \n",
      "25%     5.439365   5.505518   2.302249       27.490181  9.853282e+01   \n",
      "50%     9.728371   8.609048   4.754798       27.490181  9.853282e+01   \n",
      "75%    16.707942  12.960002   6.919309      130.460271  9.853282e+01   \n",
      "max    19.165977  19.632563  10.459712      292.905097  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   76.594467  \n",
      "std    3.834653e-07  6.398937e-08  1.279787e-07  1.919681e-07  101.305455  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   10.239510  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  141.827886  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  312.201457  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: 0.2662\n",
      "lv.v_ref: 0.0373\n",
      "la.E_act: -0.6531\n",
      "\n",
      "Best match in this wave:\n",
      "    lv.E_act  lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "12  4.797952   8.44814  0.014313        27.49018  98.532821  99.014661   \n",
      "\n",
      "    ao.P_pc1   ao.P_pc2   ao.P_pc3   CO  \n",
      "12  9.877315  19.754629  29.631944  0.0  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=0.0000, Difference=5.0000\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 1: 50 successful samples out of 50\n",
      "Wave 1: 0 not implausible points found (threshold: 3.0)\n",
      "Too few not implausible points, generating new random samples\n",
      "Generated 50 new samples for wave 2\n",
      "\n",
      "Starting wave 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 21.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean    8.824617  10.447820   5.026994       91.390765  9.853282e+01   \n",
      "std     5.439802   5.895540   2.793180       87.545319  7.069771e-07   \n",
      "min     0.035987   0.408410   0.325296       27.490181  9.853282e+01   \n",
      "25%     4.079524   5.584872   2.787769       27.490181  9.853282e+01   \n",
      "50%     9.376542  10.174185   4.883951       27.490181  9.853282e+01   \n",
      "75%    12.190645  15.709998   7.465198      156.575878  9.853282e+01   \n",
      "max    19.298929  19.914855  10.366954      312.654873  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   84.331613  \n",
      "std    2.861275e-07  4.785360e-08  9.570720e-08  1.435608e-07  104.736409  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   25.893284  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  169.218166  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  332.915197  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: 0.1448\n",
      "lv.v_ref: 0.0381\n",
      "la.E_act: -0.8191\n",
      "\n",
      "Best match in this wave:\n",
      "    lv.E_act  lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "37  4.775678  5.472486  4.295886       27.490181  98.532824  99.014662   \n",
      "\n",
      "    ao.P_pc1  ao.P_pc2   ao.P_pc3         CO  \n",
      "37  9.877315  19.75463  29.631945  31.189777  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=31.1898, Difference=26.1898\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 2: 50 successful samples out of 50\n",
      "Wave 2: 0 not implausible points found (threshold: 3.0)\n",
      "Too few not implausible points, generating new random samples\n",
      "Generated 50 new samples for wave 3\n",
      "\n",
      "Starting wave 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean   10.275035  10.895799   5.694136       75.989563  9.853282e+01   \n",
      "std     6.319334   5.926151   2.974480       83.606462  7.505564e-07   \n",
      "min     0.689308   0.371536   0.365573       27.490181  9.853282e+01   \n",
      "25%     4.902823   5.494612   3.321522       27.490181  9.853282e+01   \n",
      "50%    11.618500  11.575655   6.041751       27.490181  9.853282e+01   \n",
      "75%    16.333875  16.037865   8.186984      123.376877  9.853282e+01   \n",
      "max    19.254439  19.774163  10.149854      272.260470  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   64.075698  \n",
      "std    3.032957e-07  5.061530e-08  1.012306e-07  1.518459e-07  100.320035  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01    1.990396  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  134.398760  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  290.549190  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: -0.1483\n",
      "lv.v_ref: -0.1916\n",
      "la.E_act: -0.8203\n",
      "\n",
      "Best match in this wave:\n",
      "   lv.E_act   lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "0  4.419405  12.049388  4.648135       27.490181  98.532824  99.014662   \n",
      "\n",
      "   ao.P_pc1  ao.P_pc2   ao.P_pc3         CO  \n",
      "0  9.877315  19.75463  29.631945  31.733652  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=31.7337, Difference=26.7337\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 3: 50 successful samples out of 50\n",
      "Wave 3: 0 not implausible points found (threshold: 3.0)\n",
      "Too few not implausible points, generating new random samples\n",
      "Generated 50 new samples for wave 4\n",
      "\n",
      "Starting wave 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean    9.471556   9.194045   5.183824       80.729594  9.853282e+01   \n",
      "std     5.732415   5.681967   3.202803       81.799797  8.885387e-07   \n",
      "min     1.403774   0.491224   0.053679       27.490180  9.853282e+01   \n",
      "25%     4.503193   4.509981   2.901119       27.490181  9.853282e+01   \n",
      "50%     8.106130   9.684173   5.569519       27.490181  9.853282e+01   \n",
      "75%    14.952736  13.444006   7.904559      131.187793  9.853282e+01   \n",
      "max    19.010978  19.334205  10.498102      283.230808  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   69.886810  \n",
      "std    3.567145e-07  6.036276e-08  1.207255e-07  1.810883e-07   99.440022  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01    0.197009  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  142.590918  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  302.054978  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: -0.0701\n",
      "lv.v_ref: 0.1250\n",
      "la.E_act: -0.7258\n",
      "\n",
      "Best match in this wave:\n",
      "   lv.E_act  lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "3  3.678837  2.182891  0.076078        27.49018  98.532822  99.014661   \n",
      "\n",
      "   ao.P_pc1  ao.P_pc2   ao.P_pc3   CO  \n",
      "3  9.877315  19.75463  29.631944  0.0  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=0.0000, Difference=5.0000\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 4: 50 successful samples out of 50\n",
      "Wave 4: 0 not implausible points found (threshold: 3.0)\n",
      "Too few not implausible points, generating new random samples\n",
      "Generated 50 new samples for wave 5\n",
      "\n",
      "Starting wave 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean    9.429423   9.807267   5.847940       86.370659  9.853282e+01   \n",
      "std     5.916276   6.061291   3.082156       93.227769  7.593635e-07   \n",
      "min     0.470138   0.374447   0.105752       27.490181  9.853282e+01   \n",
      "25%     3.864679   4.754978   2.756871       27.490181  9.853282e+01   \n",
      "50%     9.001240   8.859125   6.972272       27.490181  9.853282e+01   \n",
      "75%    14.689128  15.080052   8.418483      142.403471  9.853282e+01   \n",
      "max    19.813161  19.840032  10.277867      300.519465  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   73.924771  \n",
      "std    3.074814e-07  5.135866e-08  1.027173e-07  1.540760e-07  112.027462  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01    0.000000  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  154.354020  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  320.187473  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: -0.0578\n",
      "lv.v_ref: 0.2582\n",
      "la.E_act: -0.8226\n",
      "\n",
      "Best match in this wave:\n",
      "   lv.E_act  lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "6  3.803503  9.230672  0.105752       27.490181  98.532822  99.014662   \n",
      "\n",
      "   ao.P_pc1  ao.P_pc2   ao.P_pc3        CO  \n",
      "6  9.877315  19.75463  29.631945  4.356142  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=4.3561, Difference=0.6439\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 5: 50 successful samples out of 50\n",
      "Wave 5: 0 not implausible points found (threshold: 3.0)\n",
      "\n",
      "History matching completed. Total samples: 250\n",
      "\n",
      "Best matching parameters:\n",
      "lv.E_act    4.797952\n",
      "lv.v_ref    8.448140\n",
      "la.E_act    0.014313\n",
      "Name: 12, dtype: float64\n",
      "Implausibility: 27.490180145788727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x10f40f920>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mfamili/work/env_ae/lib/python3.12/site-packages/tqdm/std.py\", line 1147, in __del__\n",
      "    def __del__(self):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting wave 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean    9.177667   9.921543   5.796905       71.959357  9.853282e+01   \n",
      "std     5.730706   5.989258   2.841052       79.678356  7.543579e-07   \n",
      "min     0.155132   0.231457   0.055696       27.490180  9.853282e+01   \n",
      "25%     4.328244   4.532313   3.155875       27.490181  9.853282e+01   \n",
      "50%     8.507186   9.636864   6.007592       27.490181  9.853282e+01   \n",
      "75%    14.259833  15.417921   7.904234       62.589351  9.853282e+01   \n",
      "max    18.639933  19.651099  10.428832      296.905357  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   59.063942  \n",
      "std    3.125707e-07  5.197297e-08  1.039459e-07  1.559189e-07   96.334799  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01    0.000000  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01   70.644265  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  316.396966  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: -0.0495\n",
      "lv.v_ref: 0.2960\n",
      "la.E_act: -0.7031\n",
      "\n",
      "Best match in this wave:\n",
      "     lv.E_act  lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "16  14.184664  6.455227  0.055696        27.49018  98.532821  99.014661   \n",
      "\n",
      "    ao.P_pc1  ao.P_pc2   ao.P_pc3   CO  \n",
      "16  9.877315  19.75463  29.631944  0.0  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=0.0000, Difference=5.0000\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 1: 50 successful samples out of 50\n",
      "Wave 1: 0 not implausible points found (threshold: 3.0)\n",
      "Too few not implausible points, generating new random samples\n",
      "Generated 50 new samples for wave 2\n",
      "\n",
      "Starting wave 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean    9.132979   9.902876   4.795985       95.898285  9.853282e+01   \n",
      "std     5.317315   5.437533   3.027693       90.654320  7.871425e-07   \n",
      "min     0.497589   0.816885   0.465025       27.490181  9.853282e+01   \n",
      "25%     4.487001   5.389273   2.367905       27.490181  9.853282e+01   \n",
      "50%     8.524874  10.414683   4.788947       27.490181  9.853282e+01   \n",
      "75%    13.436934  13.783470   6.832400      167.528167  9.853282e+01   \n",
      "max    18.747681  19.860682  10.408191      287.373166  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   89.588246  \n",
      "std    3.163094e-07  5.310055e-08  1.062011e-07  1.593017e-07  107.889060  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   18.033341  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  180.705024  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  306.399519  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: 0.0230\n",
      "lv.v_ref: 0.0884\n",
      "la.E_act: -0.8131\n",
      "\n",
      "Best match in this wave:\n",
      "    lv.E_act  lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "7  13.176353  6.854551  4.618388       27.490181  98.532824  99.014662   \n",
      "\n",
      "   ao.P_pc1  ao.P_pc2   ao.P_pc3         CO  \n",
      "7  9.877315  19.75463  29.631945  20.520826  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=20.5208, Difference=15.5208\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 2: 50 successful samples out of 50\n",
      "Wave 2: 0 not implausible points found (threshold: 3.0)\n",
      "Too few not implausible points, generating new random samples\n",
      "Generated 50 new samples for wave 3\n",
      "\n",
      "Starting wave 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output DataFrame Summary:\n",
      "        lv.E_act   lv.v_ref   la.E_act  implausibility      ao.P_min  \\\n",
      "count  50.000000  50.000000  50.000000       50.000000  5.000000e+01   \n",
      "mean   10.359544   9.284133   4.784464       88.192088  9.853282e+01   \n",
      "std     5.406666   5.484608   3.126228       90.387139  8.633285e-07   \n",
      "min     0.194032   0.119796   0.037257       27.490180  9.853282e+01   \n",
      "25%     5.132961   5.422089   1.981733       27.490181  9.853282e+01   \n",
      "50%    11.857791   9.316576   4.703831       27.490181  9.853282e+01   \n",
      "75%    14.675661  14.392492   7.083468      161.483026  9.853282e+01   \n",
      "max    19.937433  19.827405  10.264813      303.231545  9.853283e+01   \n",
      "\n",
      "           ao.P_max      ao.P_pc1      ao.P_pc2      ao.P_pc3          CO  \n",
      "count  5.000000e+01  5.000000e+01  5.000000e+01  5.000000e+01   50.000000  \n",
      "mean   9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   80.070838  \n",
      "std    3.644968e-07  6.102525e-08  1.220505e-07  1.830757e-07  107.291680  \n",
      "min    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "25%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01    0.000000  \n",
      "50%    9.901466e+01  9.877315e+00  1.975463e+01  2.963194e+01   13.988572  \n",
      "75%    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  174.364826  \n",
      "max    9.901466e+01  9.877315e+00  1.975463e+01  2.963195e+01  323.031928  \n",
      "\n",
      "Correlation between parameters and implausibility:\n",
      "lv.E_act: 0.1346\n",
      "lv.v_ref: 0.1400\n",
      "la.E_act: -0.6695\n",
      "\n",
      "Best match in this wave:\n",
      "    lv.E_act  lv.v_ref  la.E_act  implausibility   ao.P_min   ao.P_max  \\\n",
      "43  5.775754  6.244958  0.037257        27.49018  98.532821  99.014661   \n",
      "\n",
      "    ao.P_pc1  ao.P_pc2   ao.P_pc3   CO  \n",
      "43  9.877315  19.75463  29.631944  0.0  \n",
      "\n",
      "Observed vs. Best Simulated Values:\n",
      "ao.P_min: Observed=80.0000, Simulated=98.5328, Difference=18.5328\n",
      "ao.P_max: Observed=120.0000, Simulated=99.0147, Difference=20.9853\n",
      "ao.P_pc1: Observed=10.5000, Simulated=9.8773, Difference=0.6227\n",
      "ao.P_pc2: Observed=-3.2000, Simulated=19.7546, Difference=22.9546\n",
      "ao.P_pc3: Observed=0.8000, Simulated=29.6319, Difference=28.8319\n",
      "CO: Observed=5.0000, Simulated=0.0000, Difference=5.0000\n",
      "\n",
      "Output dataframe saved to 'wave_outputs.csv' for further analysis\n",
      "Wave 3: 50 successful samples out of 50\n",
      "Wave 3: 0 not implausible points found (threshold: 3.0)\n",
      "Too few not implausible points, generating new random samples\n",
      "Generated 50 new samples for wave 4\n",
      "\n",
      "Starting wave 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:00<00:01, 21.88it/s]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x10712d7f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mfamili/work/env_ae/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 524\u001b[39m\n\u001b[32m    521\u001b[39m hm = NaghaviHistoryMatcher(observed_data=observed_signals, param_ranges=param_ranges)\n\u001b[32m    523\u001b[39m \u001b[38;5;66;03m# Run history matching\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m best_samples, best_impl_scores = \u001b[43mhm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_waves\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_wave\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;66;03m# Print best match\u001b[39;00m\n\u001b[32m    527\u001b[39m best_idx = np.argmin(best_impl_scores)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 317\u001b[39m, in \u001b[36mNaghaviHistoryMatcher.history_matching\u001b[39m\u001b[34m(self, n_waves, n_samples_per_wave, n_jobs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting wave \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwave\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_waves\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# Run simulations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m successful_samples, outputs, impl_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_wave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWave \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwave+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(successful_samples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m successful samples out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(current_samples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(successful_samples) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 209\u001b[39m, in \u001b[36mNaghaviHistoryMatcher.run_wave\u001b[39m\u001b[34m(self, samples, n_jobs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Serial execution\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m tqdm(samples.iterrows(), total=\u001b[38;5;28mlen\u001b[39m(samples)):\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_single_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    211\u001b[39m         params, outputs, impl = result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 269\u001b[39m, in \u001b[36mNaghaviHistoryMatcher._run_single_sample\u001b[39m\u001b[34m(self, sample)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03mRun a single sample and calculate implausibility using HistoryMatching class\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    266\u001b[39m \u001b[33;03m    Tuple of (parameters, outputs, implausibility) or None if failed\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    268\u001b[39m params = sample.to_dict()\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mNaghaviHistoryMatcher.run_simulation\u001b[39m\u001b[34m(self, params)\u001b[39m\n\u001b[32m    111\u001b[39m solver = Solver(model=model)\n\u001b[32m    112\u001b[39m solver.setup(suppress_output=\u001b[38;5;28;01mTrue\u001b[39;00m, optimize_secondary_sv=\u001b[38;5;28;01mFalse\u001b[39;00m, conv_cols=[\u001b[33m\"\u001b[39m\u001b[33mp_ao\u001b[39m\u001b[33m\"\u001b[39m], method=\u001b[33m'\u001b[39m\u001b[33mLSODA\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m solver.converged:\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/ModularCirc/ModularCirc/Solver.py:488\u001b[39m, in \u001b[36mSolver.solve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    486\u001b[39m temp   = np.zeros(\u001b[38;5;28mself\u001b[39m._asd.iloc[:,keys4].shape)  \n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m._asd.values) :\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     line[keys4] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ms_u_update\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._optimize_secondary_sv:\n\u001b[32m    490\u001b[39m         temp[i,:] = \u001b[38;5;28mself\u001b[39m.optimize(line, keys4)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/ModularCirc/ModularCirc/Solver.py:253\u001b[39m, in \u001b[36mSolver.generate_dfdt_functions.<locals>.s_u_update\u001b[39m\u001b[34m(t, y)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34ms_u_update\u001b[39m(t, y:np.ndarray[\u001b[38;5;28mfloat\u001b[39m]) -> np.ndarray[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    240\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m    Updates the secondary state variables based on the current values of the primary state variables.\u001b[39;00m\n\u001b[32m    242\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m \u001b[33;03m        >>> s_u_update(t=0.0, y=self._asd.iloc[0].to_numpy())\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.fromiter([\u001b[43mfi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43myi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m fi, yi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(funcs2, y[ids2])], \n\u001b[32m    254\u001b[39m                        dtype=np.float64)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/ModularCirc/ModularCirc/Components/Valve_non_ideal.py:8\u001b[39m, in \u001b[36mgen_q_i_u_func.<locals>.q_i_u_func\u001b[39m\u001b[34m(t, y)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgen_q_i_u_func\u001b[39m(r, max_func):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mq_i_u_func\u001b[39m(t, y): \n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m non_ideal_diode_flow(t, y=y, r=r, max_func=max_func)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m q_i_u_func\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from ModularCirc.Models.NaghaviModel import NaghaviModel, NaghaviModelParameters\n",
    "from ModularCirc.Analysis.BaseAnalysis import BaseAnalysis\n",
    "from ModularCirc.Solver import Solver\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple, List\n",
    "from autoemulate.history_matching import HistoryMatching\n",
    "\n",
    "\n",
    "class NaghaviHistoryMatcher:\n",
    "    def __init__(self, observed_data: Dict[str, np.ndarray], \n",
    "                param_ranges: Dict[str, Tuple[float, float]],\n",
    "                n_cycles: int = 40, dt: float = 0.001,\n",
    "                implausibility_threshold: float = 3.0,\n",
    "                model_discrepancy: float = 0.0):\n",
    "        \"\"\"\n",
    "        Initialize the history matching framework for Naghavi model\n",
    "        \n",
    "        Args:\n",
    "            observed_data: Dictionary containing observed signals (keys: signal names, values: arrays)\n",
    "            param_ranges: Dictionary of parameter ranges to explore (keys: parameter names, values: (min, max))\n",
    "            n_cycles: Number of cardiac cycles to simulate\n",
    "            dt: Time step for simulation\n",
    "            implausibility_threshold: Threshold for considering points implausible\n",
    "            model_discrepancy: Model discrepancy term\n",
    "        \"\"\"\n",
    "        self.observed_data = observed_data\n",
    "        self.param_ranges = param_ranges\n",
    "        self.param_names = list(param_ranges.keys())\n",
    "        self.n_cycles = n_cycles\n",
    "        self.dt = dt\n",
    "        self.samples = None\n",
    "        self.simulator_outputs = None\n",
    "        self.gp_emulators = {}\n",
    "        \n",
    "        # Initialize the HistoryMatching object\n",
    "        self.history_matcher = HistoryMatching(\n",
    "            threshold=implausibility_threshold,\n",
    "            discrepancy=model_discrepancy,\n",
    "            rank=1\n",
    "        )\n",
    "        \n",
    "        # Time setup dictionary\n",
    "        self.time_setup = {\n",
    "            \"name\": \"HistoryMatching\",\n",
    "            \"ncycles\": n_cycles,\n",
    "            \"tcycle\": 1.0,  # Will be adjusted per simulation\n",
    "            \"dt\": dt,\n",
    "            \"export_min\": 1\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def signal_get_pulse(self, signal: np.ndarray, dt: float, num: int = 100) -> Tuple[float, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Resample raw signal to standard resolution\n",
    "        \n",
    "        Args:\n",
    "            signal: Raw signal array\n",
    "            dt: Original time resolution\n",
    "            num: Number of points in resampled signal\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (new_dt, resampled_signal)\n",
    "        \"\"\"\n",
    "        ind = np.argmin(signal)        \n",
    "        ncycle = len(signal)\n",
    "        new_signal = np.interp(np.linspace(0, ncycle, num), \n",
    "                            np.arange(ncycle), \n",
    "                            np.roll(signal, -ind))\n",
    "        new_dt = ncycle / (num - 1) * dt\n",
    "        return new_dt, new_signal\n",
    "    \n",
    "    def run_simulation(self, params: Dict[str, float]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Run a single Naghavi model simulation with given parameters\n",
    "        \n",
    "        Args:\n",
    "            params: Dictionary of parameter values\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of processed features from simulation outputs\n",
    "        \"\"\"\n",
    "        # Create parameter object\n",
    "        parobj = NaghaviModelParameters()\n",
    "        \n",
    "        # Set parameters from input\n",
    "        for param_name, value in params.items():\n",
    "            if param_name == \"T\":\n",
    "                continue  # Handle cycle time separately\n",
    "            try:\n",
    "                obj, param = param_name.split('.')\n",
    "                parobj._set_comp(obj, [obj], **{param: value})\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting parameter {param_name}: {e}\")\n",
    "                return None\n",
    "        \n",
    "        # Adjust cycle time if specified\n",
    "        t_cycle = params.get(\"T\", 1.0)\n",
    "        self.time_setup[\"tcycle\"] = t_cycle\n",
    "        \n",
    "        # Create and run model\n",
    "        try:\n",
    "            model = NaghaviModel(time_setup_dict=self.time_setup, parobj=parobj, suppress_printing=True)\n",
    "            solver = Solver(model=model)\n",
    "            solver.setup(suppress_output=True, optimize_secondary_sv=False, conv_cols=[\"p_ao\"], method='LSODA')\n",
    "            solver.solve()\n",
    "            \n",
    "            if not solver.converged:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Simulation error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Process results\n",
    "        raw_results = {}\n",
    "        \n",
    "        # Get indices for the last cycle\n",
    "        tind_fin = np.arange(start=model.time_object.n_t-model.time_object.n_c,\n",
    "                            stop=model.time_object.n_t)\n",
    "        \n",
    "        # Extract raw signals of interest\n",
    "        for signal_name in self.observed_data.keys():\n",
    "            if signal_name == \"CO\":\n",
    "                # Handle cardiac output separately\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                component, _ = signal_name.split('.')\n",
    "                # Get the pressure signal from the component\n",
    "                if component in model.components:\n",
    "                    # Extract P_i (pressure) from the component for the last cycle\n",
    "                    raw_signal = model.components[component].P_i.values[tind_fin]\n",
    "                    \n",
    "                    if '_min' in signal_name:\n",
    "                        raw_results[signal_name] = np.min(raw_signal)\n",
    "                    elif '_max' in signal_name:\n",
    "                        raw_results[signal_name] = np.max(raw_signal)\n",
    "                    elif '_pc' in signal_name:\n",
    "                        # For PCA components, you would need to implement the PCA calculation\n",
    "                        # This is a placeholder\n",
    "                        pc_index = int(signal_name.split('_pc')[1])\n",
    "                        # Simple approximation for demonstration\n",
    "                        raw_results[signal_name] = np.mean(raw_signal) * (pc_index * 0.1)\n",
    "                else:\n",
    "                    print(f\"Component {component} not found in model\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting signal {signal_name}: {e}\")\n",
    "                return None\n",
    "                \n",
    "        # Add scalar metrics\n",
    "        analysis = BaseAnalysis(model)\n",
    "        analysis.compute_cardiac_output(\"lv\")\n",
    "        raw_results[\"CO\"] = analysis.CO\n",
    "        \n",
    "        return raw_results  # Return the processed results directly\n",
    "\n",
    "    def process_simulation_output(self, raw_results: Dict[str, np.ndarray]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Process raw simulation outputs to extract features for comparison with observed data\n",
    "        \n",
    "        Args:\n",
    "            raw_results: Dictionary of raw simulation outputs\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of processed features\n",
    "        \"\"\"\n",
    "        processed = {}\n",
    "        \n",
    "        # Process each signal based on what features we want to extract\n",
    "        for signal_name, signal_data in raw_results.items():\n",
    "            if signal_name == \"CO\":\n",
    "                # Cardiac output is already a scalar\n",
    "                processed[signal_name] = signal_data\n",
    "            elif '.P' in signal_name:\n",
    "                # For pressure signals, extract min, max and other features\n",
    "                processed[f\"{signal_name}_min\"] = np.min(signal_data)\n",
    "                processed[f\"{signal_name}_max\"] = np.max(signal_data)\n",
    "                \n",
    "                # Could add more sophisticated feature extraction here\n",
    "                # For example, PCA components if needed\n",
    "            \n",
    "        return processed\n",
    "    \n",
    "    def run_wave(self, samples: pd.DataFrame, n_jobs: int = 1) -> Tuple[pd.DataFrame, List[Dict], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Run a wave of simulations\n",
    "        \n",
    "        Args:\n",
    "            samples: DataFrame of parameter samples\n",
    "            n_jobs: Number of parallel jobs\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (successful_samples, outputs, implausibility_scores)\n",
    "        \"\"\"\n",
    "        successful_samples = []\n",
    "        simulation_outputs = []\n",
    "        implausibility_scores = []\n",
    "\n",
    "        # Serial execution\n",
    "        for _, row in tqdm(samples.iterrows(), total=len(samples)):\n",
    "            result = self._run_single_sample(row)\n",
    "            if result is not None:\n",
    "                params, outputs, impl = result\n",
    "                successful_samples.append(params)\n",
    "                simulation_outputs.append(outputs)\n",
    "                implausibility_scores.append(impl)\n",
    "                        \n",
    "        # Create a dataframe with all outputs for inspection\n",
    "        if successful_samples:\n",
    "            # Combine parameters and outputs into one dataframe for inspection\n",
    "            output_df = pd.DataFrame(successful_samples)\n",
    "            \n",
    "            # Add implausibility scores\n",
    "            output_df['implausibility'] = implausibility_scores\n",
    "            \n",
    "            # Add simulation outputs for each observed signal\n",
    "            for i, output_dict in enumerate(simulation_outputs):\n",
    "                for signal_name, value in output_dict.items():\n",
    "                    if signal_name not in output_df.columns:\n",
    "                        output_df[signal_name] = np.nan\n",
    "                    output_df.at[i, signal_name] = value\n",
    "            \n",
    "            # Print summary statistics of the outputs\n",
    "            print(\"\\nOutput DataFrame Summary:\")\n",
    "            print(output_df.describe())\n",
    "            \n",
    "            # Show the relationship between parameters and implausibility\n",
    "            print(\"\\nCorrelation between parameters and implausibility:\")\n",
    "            for param in self.param_names:\n",
    "                corr = np.corrcoef(output_df[param], output_df['implausibility'])[0, 1]\n",
    "                print(f\"{param}: {corr:.4f}\")\n",
    "            \n",
    "            # Show the best match in this wave\n",
    "            best_idx = np.argmin(implausibility_scores)\n",
    "            print(\"\\nBest match in this wave:\")\n",
    "            print(output_df.iloc[[best_idx]])\n",
    "            \n",
    "            # Print the observed vs. simulated values for the best match\n",
    "            print(\"\\nObserved vs. Best Simulated Values:\")\n",
    "            for signal_name, observed_value in self.observed_data.items():\n",
    "                if signal_name in output_df.columns:\n",
    "                    simulated = output_df.iloc[best_idx][signal_name]\n",
    "                    print(f\"{signal_name}: Observed={observed_value:.4f}, Simulated={simulated:.4f}, Difference={abs(observed_value - simulated):.4f}\")\n",
    "            \n",
    "            # Save the output dataframe to a CSV file for external analysis\n",
    "            output_df.to_csv(f\"wave_outputs.csv\", index=False)\n",
    "            print(\"\\nOutput dataframe saved to 'wave_outputs.csv' for further analysis\")\n",
    "            \n",
    "        return pd.DataFrame(successful_samples), simulation_outputs, np.array(implausibility_scores)\n",
    "    def _run_single_sample(self, sample: pd.Series) -> Tuple[Dict, Dict, float]:\n",
    "        \"\"\"\n",
    "        Run a single sample and calculate implausibility using HistoryMatching class\n",
    "        \n",
    "        Args:\n",
    "            sample: Parameter values as Series\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (parameters, outputs, implausibility) or None if failed\n",
    "        \"\"\"\n",
    "        params = sample.to_dict()\n",
    "        outputs = self.run_simulation(params)\n",
    "        \n",
    "        if outputs is None:\n",
    "            return None\n",
    "            \n",
    "        # Calculate implausibility using the HistoryMatching class\n",
    "        implausibilities = []\n",
    "        \n",
    "        for signal_name, obs_value in self.observed_data.items():\n",
    "            if signal_name not in outputs:\n",
    "                print(f\"Warning: {signal_name} not found in simulation outputs\")\n",
    "                continue\n",
    "                \n",
    "            # Set up observation and prediction in format expected by HistoryMatching\n",
    "            # [mean, variance]\n",
    "            obs = [obs_value, 1.0]  # Assuming observation variance of 1.0\n",
    "            pred = [outputs[signal_name], 0.1]  # Assuming prediction variance of 0.1\n",
    "            \n",
    "            try:\n",
    "                result = self.history_matcher.history_matching(obs, pred)\n",
    "                implausibilities.append(result[\"I\"][0])  # Take the first implausibility value\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating implausibility for {signal_name}: {e}\")\n",
    "                implausibilities.append(float('inf'))  # Treat as infinitely implausible\n",
    "        \n",
    "        if not implausibilities:\n",
    "            return None  # No valid implausibility calculations\n",
    "            \n",
    "        impl = np.max(implausibilities)  # Maximum implausibility approach\n",
    "        \n",
    "        return params, outputs, impl\n",
    "    def history_matching(self, n_waves: int = 3, n_samples_per_wave: int = 100, n_jobs: int = 4):\n",
    "        \"\"\"\n",
    "        Perform iterative history matching using the HistoryMatching class\n",
    "        \n",
    "        Args:\n",
    "            n_waves: Number of waves to perform\n",
    "            n_samples_per_wave: Samples per wave\n",
    "            n_jobs: Number of parallel jobs\n",
    "        \"\"\"\n",
    "        current_samples = self.generate_samples(n_samples_per_wave)\n",
    "        all_samples = pd.DataFrame()\n",
    "        all_implausibilities = np.array([])\n",
    "        \n",
    "        for wave in range(n_waves):\n",
    "            print(f\"\\nStarting wave {wave + 1}/{n_waves}\")\n",
    "            \n",
    "            # Run simulations\n",
    "            successful_samples, outputs, impl_scores = self.run_wave(current_samples, n_jobs)\n",
    "            print(f\"Wave {wave+1}: {len(successful_samples)} successful samples out of {len(current_samples)}\")\n",
    "            \n",
    "            if len(successful_samples) == 0:\n",
    "                print(\"No successful simulations in this wave, generating new random samples\")\n",
    "                current_samples = self.generate_samples(n_samples_per_wave)\n",
    "                continue  # Try again with new samples instead of stopping\n",
    "                \n",
    "            # Store all results\n",
    "            all_samples = pd.concat([all_samples, successful_samples])\n",
    "            all_implausibilities = np.concatenate([all_implausibilities, impl_scores]) if len(all_implausibilities) > 0 else impl_scores\n",
    "            \n",
    "            # Identify not implausible points (NROY) using threshold from HistoryMatching\n",
    "            nroy_indices = np.where(impl_scores <= self.history_matcher.threshold)[0]\n",
    "            not_implausible = successful_samples.iloc[nroy_indices] if len(nroy_indices) > 0 else pd.DataFrame()\n",
    "            \n",
    "            print(f\"Wave {wave + 1}: {len(not_implausible)} not implausible points found (threshold: {self.history_matcher.threshold})\")\n",
    "            \n",
    "            # Prepare next wave samples\n",
    "            if wave < n_waves - 1:\n",
    "                if len(not_implausible) >= 2:  # Need at least 2 points for meaningful bounds\n",
    "                    try:\n",
    "                        print(\"Generating new samples based on not implausible points\")\n",
    "                        new_sample_points = self.history_matcher._sample_new_points(\n",
    "                            not_implausible[self.param_names].values, n_samples_per_wave)\n",
    "                        current_samples = pd.DataFrame(new_sample_points, columns=self.param_names)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error generating new samples: {e}\")\n",
    "                        print(\"Falling back to random sampling\")\n",
    "                        current_samples = self.generate_samples(n_samples_per_wave)\n",
    "                else:\n",
    "                    # Fall back to random sampling if too few NROY points\n",
    "                    print(\"Too few not implausible points, generating new random samples\")\n",
    "                    current_samples = self.generate_samples(n_samples_per_wave)\n",
    "                \n",
    "                print(f\"Generated {len(current_samples)} new samples for wave {wave+2}\")\n",
    "            \n",
    "            # Plot results only if we have implausible and not implausible points\n",
    "            if len(not_implausible) > 0 and len(successful_samples) > len(not_implausible):\n",
    "                self.plot_wave_results(wave, successful_samples, impl_scores, not_implausible)\n",
    "        \n",
    "        print(f\"\\nHistory matching completed. Total samples: {len(all_samples)}\")\n",
    "        \n",
    "        return all_samples, all_implausibilities\n",
    "    \n",
    "    def generate_samples(self, n_samples: int, method: str = 'random') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate parameter samples using specified method\n",
    "        \n",
    "        Args:\n",
    "            n_samples: Number of samples to generate\n",
    "            method: Sampling method ('random' or 'lhs')\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame of parameter samples\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        if method == 'random':\n",
    "            for param_name, (low, high) in self.param_ranges.items():\n",
    "                samples.append(np.random.uniform(low, high, n_samples))\n",
    "        elif method == 'lhs':\n",
    "            # Implement Latin Hypercube Sampling here if needed\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown sampling method: {method}\")\n",
    "            \n",
    "        return pd.DataFrame(np.array(samples).T, columns=self.param_names)\n",
    "    \n",
    "    def plot_wave_results(self, wave: int, samples: pd.DataFrame, \n",
    "                        impl_scores: np.ndarray, not_implausible: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Plot results from a history matching wave\n",
    "        \n",
    "        Args:\n",
    "            wave: Wave number\n",
    "            samples: All successful samples\n",
    "            impl_scores: Corresponding implausibility scores\n",
    "            not_implausible: Not implausible samples\n",
    "        \"\"\"\n",
    "        if len(self.param_names) < 2:\n",
    "            return\n",
    "            \n",
    "        # Select two main parameters to plot\n",
    "        param1, param2 = self.param_names[:2]\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot all samples colored by implausibility\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sc = plt.scatter(samples[param1], samples[param2], c=impl_scores, \n",
    "                        cmap='viridis_r', vmax=3.0)\n",
    "        plt.colorbar(sc, label='Implausibility')\n",
    "        plt.xlabel(param1)\n",
    "        plt.ylabel(param2)\n",
    "        plt.title(f'Wave {wave + 1} - All Samples')\n",
    "        \n",
    "        # Plot not implausible region\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(not_implausible[param1], not_implausible[param2], \n",
    "                c='blue', alpha=0.5)\n",
    "        plt.xlabel(param1)\n",
    "        plt.ylabel(param2)\n",
    "        plt.title(f'Wave {wave + 1} - Not Implausible Region')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def calculate_implausibility(self, sim_output: Dict[str, float], \n",
    "                            obs_error: Dict[str, float], \n",
    "                            model_error: Dict[str, float],\n",
    "                            emulator_error: Dict[str, float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Calculate combined implausibility metric across all outputs\n",
    "        \n",
    "        Args:\n",
    "            sim_output: Simulator outputs (max values)\n",
    "            obs_error: Observation errors for each output\n",
    "            model_error: Model errors for each output\n",
    "            emulator_error: Optional emulator errors\n",
    "            \n",
    "        Returns:\n",
    "            Combined implausibility score\n",
    "        \"\"\"\n",
    "        total_implausibility = 0.0\n",
    "        \n",
    "        for signal_name, obs_value in self.observed_data.items():\n",
    "            sim_value = sim_output[signal_name]\n",
    "            error = obs_error.get(signal_name, 0.1)\n",
    "            m_error = model_error.get(signal_name, 0.05)\n",
    "            \n",
    "            # Add emulator error if provided\n",
    "            e_error = emulator_error.get(signal_name, 0.0) if emulator_error else 0.0\n",
    "            \n",
    "            # Calculate absolute difference\n",
    "            diff = np.abs(sim_value - obs_value)\n",
    "            impl = diff / np.sqrt(error**2 + m_error**2 + e_error**2)\n",
    "            total_implausibility += impl\n",
    "                \n",
    "        return total_implausibility\n",
    "\n",
    "    def calculate_implausibility(self, sim_output: Dict[str, float], \n",
    "                                obs_error: Dict[str, float], \n",
    "                                model_error: Dict[str, float],\n",
    "                                emulator_error: Dict[str, float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Calculate combined implausibility metric across all processed outputs\n",
    "        \n",
    "        Args:\n",
    "            sim_output: Simulator processed outputs\n",
    "            obs_error: Observation errors for each output\n",
    "            model_error: Model errors for each output\n",
    "            emulator_error: Optional emulator errors\n",
    "            \n",
    "        Returns:\n",
    "            Combined implausibility score\n",
    "        \"\"\"\n",
    "        implausibilities = []\n",
    "        \n",
    "        for signal_name, obs_value in self.observed_data.items():\n",
    "            if signal_name not in sim_output:\n",
    "                print(f\"Warning: {signal_name} not in simulation output\")\n",
    "                continue\n",
    "                \n",
    "            sim_value = sim_output[signal_name]\n",
    "            error = obs_error.get(signal_name, 0.1)\n",
    "            m_error = model_error.get(signal_name, 0.05)\n",
    "            \n",
    "            # Add emulator error if provided\n",
    "            e_error = emulator_error.get(signal_name, 0.0) if emulator_error else 0.0\n",
    "            \n",
    "            # Calculate absolute difference\n",
    "            diff = np.abs(sim_value - obs_value)\n",
    "            impl = diff / np.sqrt(error**2 + m_error**2 + e_error**2)\n",
    "            implausibilities.append(impl)\n",
    "                \n",
    "        # Return maximum implausibility (conservative approach)\n",
    "        # Alternative: return np.mean(implausibilities) for average implausibility\n",
    "        return np.max(implausibilities)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define observed data (would normally load from file)\n",
    "\n",
    "    observed_signals = {\n",
    "        \"ao.P_min\": 80.0,    # Minimum observed aortic pressure (mmHg)\n",
    "        \"ao.P_max\": 120.0,   # Maximum observed aortic pressure (mmHg)\n",
    "        \"ao.P_pc1\": 10.5,    # First PCA component of aortic pressure\n",
    "        \"ao.P_pc2\": -3.2,    # Second PCA component of aortic pressure\n",
    "        \"ao.P_pc3\": 0.8,     # Third PCA component of aortic pressure\n",
    "        \"CO\": 5.0            # Observed cardiac output in L/min\n",
    "    }\n",
    "\n",
    "\n",
    "# Updated parameter ranges\n",
    "    param_ranges = {\n",
    "        \"lv.E_act\": (0.0, 20.0),  # LV active elastance (similar to end-systolic elastance)\n",
    "        \"lv.v_ref\": (0.0, 20.0),  # LV reference volume (similar to dead volume)\n",
    "        \"la.E_act\": (0., 10.5),   # LA active elastance\n",
    "        # For systemic arterial resistance, we need to check what parameter name to use\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Create history matcher instance\n",
    "    hm = NaghaviHistoryMatcher(observed_data=observed_signals, param_ranges=param_ranges)\n",
    "    \n",
    "    # Run history matching\n",
    "    best_samples, best_impl_scores = hm.history_matching(n_waves=5, n_samples_per_wave=50)\n",
    "    \n",
    "    # Print best match\n",
    "    best_idx = np.argmin(best_impl_scores)\n",
    "    print(\"\\nBest matching parameters:\")\n",
    "    print(best_samples.iloc[best_idx])\n",
    "    print(f\"Implausibility: {best_impl_scores[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from ModularCirc.Models.NaghaviModel import NaghaviModel, NaghaviModelParameters\n",
    "from ModularCirc.Analysis.BaseAnalysis import BaseAnalysis\n",
    "from ModularCirc.Solver import Solver\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple, List\n",
    "from autoemulate.history_matching import HistoryMatching\n",
    "\n",
    "\n",
    "class NaghaviHistoryMatcher:\n",
    "    def __init__(self, observed_data: Dict[str, np.ndarray], \n",
    "                 param_ranges: Dict[str, Tuple[float, float]],\n",
    "                 n_cycles: int = 40, dt: float = 0.001,\n",
    "                 implausibility_threshold: float = 3.0,\n",
    "                 model_discrepancy: float = 0.0):\n",
    "        \"\"\"\n",
    "        Initialize the history matching framework for Naghavi model\n",
    "        \n",
    "        Args:\n",
    "            observed_data: Dictionary containing observed signals (keys: signal names, values: arrays)\n",
    "            param_ranges: Dictionary of parameter ranges to explore (keys: parameter names, values: (min, max))\n",
    "            n_cycles: Number of cardiac cycles to simulate\n",
    "            dt: Time step for simulation\n",
    "            implausibility_threshold: Threshold for considering points implausible\n",
    "            model_discrepancy: Model discrepancy term\n",
    "        \"\"\"\n",
    "        self.observed_data = observed_data\n",
    "        self.param_ranges = param_ranges\n",
    "        self.param_names = list(param_ranges.keys())\n",
    "        self.n_cycles = n_cycles\n",
    "        self.dt = dt\n",
    "        self.samples = None\n",
    "        self.simulator_outputs = None\n",
    "        self.gp_emulators = {}\n",
    "        \n",
    "        # Initialize the HistoryMatching object\n",
    "        self.history_matcher = HistoryMatching(\n",
    "            threshold=implausibility_threshold,\n",
    "            discrepancy=model_discrepancy,\n",
    "            rank=1\n",
    "        )\n",
    "        \n",
    "        # Time setup dictionary\n",
    "        self.time_setup = {\n",
    "            \"name\": \"HistoryMatching\",\n",
    "            \"ncycles\": n_cycles,\n",
    "            \"tcycle\": 1.0,  # Will be adjusted per simulation\n",
    "            \"dt\": dt,\n",
    "            \"export_min\": 1\n",
    "        }\n",
    "        # Initialize emulator\n",
    "        self.emulator = None\n",
    "        self.emulator_trained = False\n",
    "\n",
    "    def train_emulator(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"Train the GP emulator using autoemulate\"\"\"\n",
    "        from autoemulate.compare import AutoEmulate\n",
    "        \n",
    "        print(\"Training GP emulator...\")\n",
    "        em = AutoEmulate()\n",
    "        em.setup(X, y, models=[\"gp\"])\n",
    "        self.emulator = em.compare()\n",
    "        self.emulator_trained = True\n",
    "        print(\"GP emulator trained successfully\")\n",
    "        \n",
    "    def get_emulator_predictions(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Get predictions from trained emulator\"\"\"\n",
    "        if not self.emulator_trained:\n",
    "            raise ValueError(\"Emulator not trained yet\")\n",
    "            \n",
    "        pred_mean, pred_std = self.emulator.predict(X, return_std=True)\n",
    "        pred_var = np.square(pred_std)\n",
    "        return pred_mean, pred_var\n",
    "\n",
    "    def signal_get_pulse(self, signal: np.ndarray, dt: float, num: int = 100) -> Tuple[float, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Resample raw signal to standard resolution\n",
    "        \n",
    "        Args:\n",
    "            signal: Raw signal array\n",
    "            dt: Original time resolution\n",
    "            num: Number of points in resampled signal\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (new_dt, resampled_signal)\n",
    "        \"\"\"\n",
    "        ind = np.argmin(signal)        \n",
    "        ncycle = len(signal)\n",
    "        new_signal = np.interp(np.linspace(0, ncycle, num), \n",
    "                              np.arange(ncycle), \n",
    "                              np.roll(signal, -ind))\n",
    "        new_dt = ncycle / (num - 1) * dt\n",
    "        return new_dt, new_signal\n",
    "    \n",
    "    def run_simulation(self, params: Dict[str, float]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Run a single Naghavi model simulation with given parameters\n",
    "        \n",
    "        Args:\n",
    "            params: Dictionary of parameter values\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of processed features from simulation outputs\n",
    "        \"\"\"\n",
    "        # Create parameter object\n",
    "        parobj = NaghaviModelParameters()\n",
    "        \n",
    "        # Set parameters from input\n",
    "        for param_name, value in params.items():\n",
    "            if param_name == \"T\":\n",
    "                continue  # Handle cycle time separately\n",
    "            try:\n",
    "                obj, param = param_name.split('.')\n",
    "                parobj._set_comp(obj, [obj], **{param: value})\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting parameter {param_name}: {e}\")\n",
    "                return None\n",
    "        \n",
    "        # Adjust cycle time if specified\n",
    "        t_cycle = params.get(\"T\", 1.0)\n",
    "        self.time_setup[\"tcycle\"] = t_cycle\n",
    "        \n",
    "        # Create and run model\n",
    "        try:\n",
    "            model = NaghaviModel(time_setup_dict=self.time_setup, parobj=parobj, suppress_printing=True)\n",
    "            solver = Solver(model=model)\n",
    "            solver.setup(suppress_output=True, optimize_secondary_sv=False, conv_cols=[\"p_ao\"], method='LSODA')\n",
    "            solver.solve()\n",
    "            \n",
    "            if not solver.converged:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Simulation error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Process results\n",
    "        raw_results = {}\n",
    "        \n",
    "        # Get indices for the last cycle\n",
    "        tind_fin = np.arange(start=model.time_object.n_t-model.time_object.n_c,\n",
    "                            stop=model.time_object.n_t)\n",
    "        \n",
    "        # Extract raw signals of interest - only min and max values\n",
    "        for signal_name in self.observed_data.keys():\n",
    "            try:\n",
    "                component, _ = signal_name.split('.')\n",
    "                # Get the pressure signal from the component\n",
    "                if component in model.components:\n",
    "                    # Extract P_i (pressure) from the component for the last cycle\n",
    "                    raw_signal = model.components[component].P_i.values[tind_fin]\n",
    "                    \n",
    "                    if '_min' in signal_name:\n",
    "                        raw_results[signal_name] = np.min(raw_signal)\n",
    "                    elif '_max' in signal_name:\n",
    "                        raw_results[signal_name] = np.max(raw_signal)\n",
    "                else:\n",
    "                    print(f\"Component {component} not found in model\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting signal {signal_name}: {e}\")\n",
    "                return None\n",
    "                \n",
    "        return raw_results  # Return the processed results directly\n",
    "\n",
    "    def process_simulation_output(self, raw_results: Dict[str, np.ndarray]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Process raw simulation outputs to extract features for comparison with observed data\n",
    "        \n",
    "        Args:\n",
    "            raw_results: Dictionary of raw simulation outputs\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of processed features\n",
    "        \"\"\"\n",
    "        processed = {}\n",
    "        \n",
    "        # Process each signal based on what features we want to extract\n",
    "        for signal_name, signal_data in raw_results.items():\n",
    "            if '.P' in signal_name:\n",
    "                # For pressure signals, extract min and max\n",
    "                if '_min' in signal_name:\n",
    "                    processed[f\"{signal_name}\"] = np.min(signal_data)\n",
    "                elif '_max' in signal_name:\n",
    "                    processed[f\"{signal_name}\"] = np.max(signal_data)\n",
    "            \n",
    "        return processed\n",
    "    \n",
    "    def run_wave(self, samples: pd.DataFrame, n_jobs: int = 1) -> Tuple[pd.DataFrame, List[Dict], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Run a wave of simulations\n",
    "        \n",
    "        Args:\n",
    "            samples: DataFrame of parameter samples\n",
    "            n_jobs: Number of parallel jobs\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (successful_samples, outputs, implausibility_scores)\n",
    "        \"\"\"\n",
    "        successful_samples = []\n",
    "        simulation_outputs = []\n",
    "        implausibility_scores = []\n",
    "\n",
    "        # Serial execution\n",
    "        for _, row in tqdm(samples.iterrows(), total=len(samples)):\n",
    "            result = self._run_single_sample(row)\n",
    "            if result is not None:\n",
    "                params, outputs, impl = result\n",
    "                successful_samples.append(params)\n",
    "                simulation_outputs.append(outputs)\n",
    "                implausibility_scores.append(impl)\n",
    "                        \n",
    "        # Create a dataframe with all outputs for inspection\n",
    "        if successful_samples:\n",
    "            # Combine parameters and outputs into one dataframe for inspection\n",
    "            output_df = pd.DataFrame(successful_samples)\n",
    "            \n",
    "            # Add implausibility scores\n",
    "            output_df['implausibility'] = implausibility_scores\n",
    "            \n",
    "            # Add simulation outputs for each observed signal\n",
    "            for i, output_dict in enumerate(simulation_outputs):\n",
    "                for signal_name, value in output_dict.items():\n",
    "                    if signal_name not in output_df.columns:\n",
    "                        output_df[signal_name] = np.nan\n",
    "                    output_df.at[i, signal_name] = value\n",
    "            \n",
    "            # Print summary statistics of the outputs\n",
    "            print(\"\\nOutput DataFrame Summary:\")\n",
    "            print(output_df.describe())\n",
    "            \n",
    "            # Show the relationship between parameters and implausibility\n",
    "            print(\"\\nCorrelation between parameters and implausibility:\")\n",
    "            for param in self.param_names:\n",
    "                corr = np.corrcoef(output_df[param], output_df['implausibility'])[0, 1]\n",
    "                print(f\"{param}: {corr:.4f}\")\n",
    "            \n",
    "            # Show the best match in this wave\n",
    "            best_idx = np.argmin(implausibility_scores)\n",
    "            print(\"\\nBest match in this wave:\")\n",
    "            print(output_df.iloc[[best_idx]])\n",
    "            \n",
    "            # Print the observed vs. simulated values for the best match\n",
    "            print(\"\\nObserved vs. Best Simulated Values:\")\n",
    "            for signal_name, observed_value in self.observed_data.items():\n",
    "                if signal_name in output_df.columns:\n",
    "                    simulated = output_df.iloc[best_idx][signal_name]\n",
    "                    print(f\"{signal_name}: Observed={observed_value:.4f}, Simulated={simulated:.4f}, Difference={abs(observed_value - simulated):.4f}\")\n",
    "            \n",
    "            # Save the output dataframe to a CSV file for external analysis\n",
    "            output_df.to_csv(f\"wave_outputs.csv\", index=False)\n",
    "            print(\"\\nOutput dataframe saved to 'wave_outputs.csv' for further analysis\")\n",
    "            \n",
    "        return pd.DataFrame(successful_samples), simulation_outputs, np.array(implausibility_scores)\n",
    "    \n",
    "    \n",
    "    def _run_single_sample(self, sample: pd.Series) -> Tuple[Dict, Dict, float]:\n",
    "        \"\"\"\n",
    "        Run a single sample and calculate implausibility using emulator if available\n",
    "        \"\"\"\n",
    "        params = sample.to_dict()\n",
    "        outputs = self.run_simulation(params)\n",
    "        \n",
    "        if outputs is None:\n",
    "            return None\n",
    "            \n",
    "        # Prepare predictions and observations for history matching\n",
    "        predictions = []\n",
    "        observations = []\n",
    "        \n",
    "        for signal_name, obs_value in self.observed_data.items():\n",
    "            if signal_name not in outputs:\n",
    "                print(f\"Warning: {signal_name} not found in simulation outputs\")\n",
    "                continue\n",
    "                \n",
    "            # For direct simulation (no emulator)\n",
    "            pred_mean = outputs[signal_name]\n",
    "            pred_var = 0.01  # Small fixed variance for direct simulation\n",
    "            \n",
    "            # For emulator, we would use:\n",
    "            # pred_mean, pred_var = self.get_emulator_predictions(...)\n",
    "            \n",
    "            predictions.append([pred_mean, pred_var])\n",
    "            observations.append([obs_value, 0.1])  # obs_value and obs_variance\n",
    "            \n",
    "        if not predictions:\n",
    "            return None\n",
    "            \n",
    "        # Calculate implausibility using HistoryMatching\n",
    "        try:\n",
    "            result = self.history_matcher.history_matching(observations, predictions)\n",
    "            impl = result[\"I\"][0]  # Take the first implausibility value\n",
    "            return params, outputs, impl\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating implausibility: {e}\")\n",
    "            return None\n",
    "            \n",
    "    def history_matching(self, n_waves: int = 3, n_samples_per_wave: int = 100, n_jobs: int = 4):\n",
    "        \"\"\"\n",
    "        Perform iterative history matching using the HistoryMatching class\n",
    "        \n",
    "        Args:\n",
    "            n_waves: Number of waves to perform\n",
    "            n_samples_per_wave: Samples per wave\n",
    "            n_jobs: Number of parallel jobs\n",
    "        \"\"\"\n",
    "        current_samples = self.generate_samples(n_samples_per_wave)\n",
    "        all_samples = pd.DataFrame()\n",
    "        all_implausibilities = np.array([])\n",
    "        \n",
    "        for wave in range(n_waves):\n",
    "            print(f\"\\nStarting wave {wave + 1}/{n_waves}\")\n",
    "            \n",
    "            # Run simulations\n",
    "            successful_samples, outputs, impl_scores = self.run_wave(current_samples, n_jobs)\n",
    "            print(f\"Wave {wave+1}: {len(successful_samples)} successful samples out of {len(current_samples)}\")\n",
    "            \n",
    "            if len(successful_samples) == 0:\n",
    "                print(\"No successful simulations in this wave, generating new random samples\")\n",
    "                current_samples = self.generate_samples(n_samples_per_wave)\n",
    "                continue  # Try again with new samples instead of stopping\n",
    "                \n",
    "            # Store all results\n",
    "            all_samples = pd.concat([all_samples, successful_samples])\n",
    "            all_implausibilities = np.concatenate([all_implausibilities, impl_scores]) if len(all_implausibilities) > 0 else impl_scores\n",
    "            \n",
    "            # Identify not implausible points (NROY) using threshold from HistoryMatching\n",
    "            nroy_indices = np.where(impl_scores <= self.history_matcher.threshold)[0]\n",
    "            not_implausible = successful_samples.iloc[nroy_indices] if len(nroy_indices) > 0 else pd.DataFrame()\n",
    "            \n",
    "            print(f\"Wave {wave + 1}: {len(not_implausible)} not implausible points found (threshold: {self.history_matcher.threshold})\")\n",
    "            \n",
    "            # Prepare next wave samples\n",
    "            if wave < n_waves - 1:\n",
    "                if len(not_implausible) >= 2:  # Need at least 2 points for meaningful bounds\n",
    "                    try:\n",
    "                        print(\"Generating new samples based on not implausible points\")\n",
    "                        new_sample_points = self.history_matcher._sample_new_points(\n",
    "                            not_implausible[self.param_names].values, n_samples_per_wave)\n",
    "                        current_samples = pd.DataFrame(new_sample_points, columns=self.param_names)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error generating new samples: {e}\")\n",
    "                        print(\"Falling back to random sampling\")\n",
    "                        current_samples = self.generate_samples(n_samples_per_wave)\n",
    "                else:\n",
    "                    # Fall back to random sampling if too few NROY points\n",
    "                    print(\"Too few not implausible points, generating new random samples\")\n",
    "                    current_samples = self.generate_samples(n_samples_per_wave)\n",
    "                \n",
    "                print(f\"Generated {len(current_samples)} new samples for wave {wave+2}\")\n",
    "            \n",
    "            # Plot results only if we have implausible and not implausible points\n",
    "            if len(not_implausible) > 0 and len(successful_samples) > len(not_implausible):\n",
    "                self.plot_wave_results(wave, successful_samples, impl_scores, not_implausible)\n",
    "        \n",
    "        print(f\"\\nHistory matching completed. Total samples: {len(all_samples)}\")\n",
    "        \n",
    "        return all_samples, all_implausibilities\n",
    "    \n",
    "    def generate_samples(self, n_samples: int, method: str = 'random') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate parameter samples using specified method\n",
    "        \n",
    "        Args:\n",
    "            n_samples: Number of samples to generate\n",
    "            method: Sampling method ('random' or 'lhs')\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame of parameter samples\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        if method == 'random':\n",
    "            for param_name, (low, high) in self.param_ranges.items():\n",
    "                samples.append(np.random.uniform(low, high, n_samples))\n",
    "        elif method == 'lhs':\n",
    "            # Implement Latin Hypercube Sampling here if needed\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown sampling method: {method}\")\n",
    "            \n",
    "        return pd.DataFrame(np.array(samples).T, columns=self.param_names)\n",
    "    \n",
    "    def plot_wave_results(self, wave: int, samples: pd.DataFrame, \n",
    "                         impl_scores: np.ndarray, not_implausible: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Plot results from a history matching wave\n",
    "        \n",
    "        Args:\n",
    "            wave: Wave number\n",
    "            samples: All successful samples\n",
    "            impl_scores: Corresponding implausibility scores\n",
    "            not_implausible: Not implausible samples\n",
    "        \"\"\"\n",
    "        if len(self.param_names) < 2:\n",
    "            return\n",
    "            \n",
    "        # Select two main parameters to plot\n",
    "        param1, param2 = self.param_names[:2]\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot all samples colored by implausibility\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sc = plt.scatter(samples[param1], samples[param2], c=impl_scores, \n",
    "                        cmap='viridis_r', vmax=3.0)\n",
    "        plt.colorbar(sc, label='Implausibility')\n",
    "        plt.xlabel(param1)\n",
    "        plt.ylabel(param2)\n",
    "        plt.title(f'Wave {wave + 1} - All Samples')\n",
    "        \n",
    "        # Plot not implausible region\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(not_implausible[param1], not_implausible[param2], \n",
    "                  c='blue', alpha=0.5)\n",
    "        plt.xlabel(param1)\n",
    "        plt.ylabel(param2)\n",
    "        plt.title(f'Wave {wave + 1} - Not Implausible Region')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def calculate_implausibility(self, sim_output: Dict[str, float], \n",
    "                            obs_error: Dict[str, float], \n",
    "                            model_error: Dict[str, float],\n",
    "                            emulator_error: Dict[str, float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Calculate combined implausibility metric across all outputs\n",
    "        \n",
    "        Args:\n",
    "            sim_output: Simulator outputs (max values)\n",
    "            obs_error: Observation errors for each output\n",
    "            model_error: Model errors for each output\n",
    "            emulator_error: Optional emulator errors\n",
    "            \n",
    "        Returns:\n",
    "            Combined implausibility score\n",
    "        \"\"\"\n",
    "        total_implausibility = 0.0\n",
    "        \n",
    "        for signal_name, obs_value in self.observed_data.items():\n",
    "            sim_value = sim_output[signal_name]\n",
    "            error = obs_error.get(signal_name, 0.1)\n",
    "            m_error = model_error.get(signal_name, 0.05)\n",
    "            \n",
    "            # Add emulator error if provided\n",
    "            e_error = emulator_error.get(signal_name, 0.0) if emulator_error else 0.0\n",
    "            \n",
    "            # Calculate absolute difference\n",
    "            diff = np.abs(sim_value - obs_value)\n",
    "            impl = diff / np.sqrt(error**2 + m_error**2 + e_error**2)\n",
    "            total_implausibility += impl\n",
    "                \n",
    "        return total_implausibility\n",
    "\n",
    "    def calculate_implausibility(self, sim_output: Dict[str, float], \n",
    "                                obs_error: Dict[str, float], \n",
    "                                model_error: Dict[str, float],\n",
    "                                emulator_error: Dict[str, float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Calculate combined implausibility metric across all processed outputs\n",
    "        \n",
    "        Args:\n",
    "            sim_output: Simulator processed outputs\n",
    "            obs_error: Observation errors for each output\n",
    "            model_error: Model errors for each output\n",
    "            emulator_error: Optional emulator errors\n",
    "            \n",
    "        Returns:\n",
    "            Combined implausibility score\n",
    "        \"\"\"\n",
    "        implausibilities = []\n",
    "        \n",
    "        for signal_name, obs_value in self.observed_data.items():\n",
    "            if signal_name not in sim_output:\n",
    "                print(f\"Warning: {signal_name} not in simulation output\")\n",
    "                continue\n",
    "                \n",
    "            sim_value = sim_output[signal_name]\n",
    "            error = obs_error.get(signal_name, 0.1)\n",
    "            m_error = model_error.get(signal_name, 0.05)\n",
    "            \n",
    "            # Add emulator error if provided\n",
    "            e_error = emulator_error.get(signal_name, 0.0) if emulator_error else 0.0\n",
    "            \n",
    "            # Calculate absolute difference\n",
    "            diff = np.abs(sim_value - obs_value)\n",
    "            impl = diff / np.sqrt(error**2 + m_error**2 + e_error**2)\n",
    "            implausibilities.append(impl)\n",
    "                \n",
    "        # Return maximum implausibility (conservative approach)\n",
    "        # Alternative: return np.mean(implausibilities) for average implausibility\n",
    "        return np.max(implausibilities)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define observed data (would normally load from file)\n",
    "    observed_signals = {\n",
    "        \"ao.P_min\": 80.0,    # Minimum observed aortic pressure (mmHg)\n",
    "        \"ao.P_max\": 120.0,   # Maximum observed aortic pressure (mmHg)\n",
    "    }\n",
    "\n",
    "    # Updated parameter ranges\n",
    "    param_ranges = {\n",
    "        \"lv.E_act\": (0.0, 20.0),  # LV active elastance (similar to end-systolic elastance)\n",
    "        \"lv.v_ref\": (0.0, 20.0),  # LV reference volume (similar to dead volume)\n",
    "        \"la.E_act\": (0., 10.5),   # LA active elastance\n",
    "        # For systemic arterial resistance, we need to check what parameter name to use\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Create history matcher instance\n",
    "    hm = NaghaviHistoryMatcher(observed_data=observed_signals, param_ranges=param_ranges)\n",
    "    \n",
    "    # Run history matching\n",
    "    best_samples, best_impl_scores = hm.history_matching(n_waves=5, n_samples_per_wave=50)\n",
    "    \n",
    "    # Print best match\n",
    "    best_idx = np.argmin(best_impl_scores)\n",
    "    print(\"\\nBest matching parameters:\")\n",
    "    print(best_samples.iloc[best_idx])\n",
    "    print(f\"Implausibility: {best_impl_scores[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple, List\n",
    "from autoemulate.compare import AutoEmulate\n",
    "from autoemulate.history_matching import HistoryMatching\n",
    "from ModularCirc.Models.NaghaviModel import NaghaviModel, NaghaviModelParameters\n",
    "from ModularCirc.Solver import Solver\n",
    "\n",
    "class NaghaviHistoryMatcher:\n",
    "    def __init__(self, observed_data: Dict[str, float], \n",
    "                 param_ranges: Dict[str, Tuple[float, float]],\n",
    "                 n_cycles: int = 40, dt: float = 0.001,\n",
    "                 implausibility_threshold: float = 3.0,\n",
    "                 model_discrepancy: float = 0.0):\n",
    "        \"\"\"\n",
    "        Initialize the history matching framework for Naghavi model\n",
    "        \n",
    "        Args:\n",
    "            observed_data: Dictionary of target values {signal_name: target_value}\n",
    "            param_ranges: Dictionary of parameter ranges {param_name: (min, max)}\n",
    "            n_cycles: Number of cardiac cycles to simulate\n",
    "            dt: Time step for simulation\n",
    "            implausibility_threshold: Threshold for implausibility\n",
    "            model_discrepancy: Model discrepancy term\n",
    "        \"\"\"\n",
    "        self.observed_data = observed_data\n",
    "        self.param_ranges = param_ranges\n",
    "        self.param_names = list(param_ranges.keys())\n",
    "        self.n_cycles = n_cycles\n",
    "        self.dt = dt\n",
    "        \n",
    "        # Time setup dictionary\n",
    "        self.time_setup = {\n",
    "            \"name\": \"HistoryMatching\",\n",
    "            \"ncycles\": n_cycles,\n",
    "            \"tcycle\": 1.0,\n",
    "            \"dt\": dt,\n",
    "            \"export_min\": 1\n",
    "        }\n",
    "        \n",
    "        # Initialize emulator\n",
    "        self.emulator = None\n",
    "        self.emulator_trained = False\n",
    "        \n",
    "        # History matching setup\n",
    "        self.history_matcher = HistoryMatching(\n",
    "            threshold=implausibility_threshold,\n",
    "            discrepancy=model_discrepancy,\n",
    "            rank=1\n",
    "        )\n",
    "\n",
    "    def run_simulation(self, params: Dict[str, float]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Run a single Naghavi model simulation with given parameters\n",
    "        Returns dictionary of output values {signal_name: value}\n",
    "        \"\"\"\n",
    "        # Create parameter object\n",
    "        parobj = NaghaviModelParameters()\n",
    "        \n",
    "        # Set parameters from input\n",
    "        for param_name, value in params.items():\n",
    "            if param_name == \"T\":\n",
    "                continue  # Handle cycle time separately\n",
    "            try:\n",
    "                obj, param = param_name.split('.')\n",
    "                parobj._set_comp(obj, [obj], **{param: value})\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting parameter {param_name}: {e}\")\n",
    "                return None\n",
    "        \n",
    "        # Adjust cycle time if specified\n",
    "        t_cycle = params.get(\"T\", 1.0)\n",
    "        self.time_setup[\"tcycle\"] = t_cycle\n",
    "        \n",
    "        # Create and run model\n",
    "        try:\n",
    "            model = NaghaviModel(time_setup_dict=self.time_setup, parobj=parobj, suppress_printing=True)\n",
    "            solver = Solver(model=model)\n",
    "            solver.setup(suppress_output=True, optimize_secondary_sv=False, conv_cols=[\"p_ao\"], method='LSODA')\n",
    "            solver.solve()\n",
    "            \n",
    "            if not solver.converged:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Simulation error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Process results - extract last cycle min/max values\n",
    "        raw_results = {}\n",
    "        tind_fin = np.arange(start=model.time_object.n_t-model.time_object.n_c,\n",
    "                            stop=model.time_object.n_t)\n",
    "        \n",
    "        for signal_name in self.observed_data.keys():\n",
    "            try:\n",
    "                component, _ = signal_name.split('.')\n",
    "                if component in model.components:\n",
    "                    raw_signal = model.components[component].P_i.values[tind_fin]\n",
    "                    \n",
    "                    if '_min' in signal_name:\n",
    "                        raw_results[signal_name] = np.min(raw_signal)\n",
    "                    elif '_max' in signal_name:\n",
    "                        raw_results[signal_name] = np.max(raw_signal)\n",
    "                else:\n",
    "                    print(f\"Component {component} not found in model\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting signal {signal_name}: {e}\")\n",
    "                return None\n",
    "                \n",
    "        return raw_results\n",
    "\n",
    "    def train_emulator(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"Train the GP emulator using autoemulate\"\"\"\n",
    "        print(\"Training GP emulator...\")\n",
    "        em = AutoEmulate()\n",
    "        em.setup(X, y, models=[\"gp\"])\n",
    "        self.emulator = em.compare()\n",
    "        self.emulator_trained = True\n",
    "        print(f\"GP emulator trained on {len(X)} samples\")\n",
    "\n",
    "    def get_emulator_predictions(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Get predictions from trained emulator\n",
    "        Returns:\n",
    "            pred_mean: Array of shape (n_samples, n_outputs)\n",
    "            pred_var: Array of shape (n_samples, n_outputs)\n",
    "        \"\"\"\n",
    "        if not self.emulator_trained:\n",
    "            raise ValueError(\"Emulator not trained yet\")\n",
    "            \n",
    "        pred_mean, pred_std = self.emulator.predict(X, return_std=True)\n",
    "        pred_var = np.square(pred_std)\n",
    "        return pred_mean, pred_var\n",
    "\n",
    "    def generate_samples(self, n_samples: int) -> pd.DataFrame:\n",
    "        \"\"\"Generate random parameter samples\"\"\"\n",
    "        samples = []\n",
    "        for param_name, (low, high) in self.param_ranges.items():\n",
    "            samples.append(np.random.uniform(low, high, n_samples))\n",
    "        return pd.DataFrame(np.array(samples).T, columns=self.param_names)\n",
    "\n",
    "    def run_wave(self, samples: pd.DataFrame, use_emulator: bool = False) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Run a wave of simulations or emulator predictions\n",
    "        Returns:\n",
    "            successful_samples: DataFrame of parameter sets\n",
    "            impl_scores: Array of implausibility scores\n",
    "        \"\"\"\n",
    "        if use_emulator and self.emulator_trained:\n",
    "            # Use emulator for predictions\n",
    "            X = samples[self.param_names].values\n",
    "            pred_mean, pred_var = self.get_emulator_predictions(X)\n",
    "            \n",
    "            # Calculate implausibility for each sample\n",
    "            impl_scores = []\n",
    "            for i in range(len(samples)):\n",
    "                predictions = [[pred_mean[i,j], pred_var[i,j]] \n",
    "                              for j in range(len(self.observed_data))]\n",
    "                observations = [[obs, 0.1] for obs in self.observed_data.values()]\n",
    "                \n",
    "                result = self.history_matcher.history_matching(observations, predictions)\n",
    "                impl_scores.append(result[\"I\"][0])\n",
    "                \n",
    "            return samples, np.array(impl_scores)\n",
    "        else:\n",
    "            # Run actual simulations\n",
    "            successful_samples = []\n",
    "            impl_scores = []\n",
    "            \n",
    "            for _, row in tqdm(samples.iterrows(), total=len(samples)):\n",
    "                params = row.to_dict()\n",
    "                outputs = self.run_simulation(params)\n",
    "                \n",
    "                if outputs is None:\n",
    "                    continue\n",
    "                    \n",
    "                # Prepare predictions and observations\n",
    "                predictions = [[outputs[signal], 0.01]  # Small fixed variance\n",
    "                              for signal in self.observed_data]\n",
    "                observations = [[obs, 0.1]  # Observation variance\n",
    "                              for obs in self.observed_data.values()]\n",
    "                \n",
    "                result = self.history_matcher.history_matching(observations, predictions)\n",
    "                impl_scores.append(result[\"I\"][0])\n",
    "                successful_samples.append(params)\n",
    "            \n",
    "            return pd.DataFrame(successful_samples), np.array(impl_scores)\n",
    "\n",
    "    def history_matching(self, n_waves: int = 3, n_samples_per_wave: int = 100, \n",
    "                        use_emulator: bool = False):\n",
    "        \"\"\"\n",
    "        Perform iterative history matching\n",
    "        Returns:\n",
    "            all_samples: DataFrame of all evaluated parameter sets\n",
    "            all_impl_scores: Array of corresponding implausibility scores\n",
    "        \"\"\"\n",
    "        current_samples = self.generate_samples(n_samples_per_wave)\n",
    "        all_samples = pd.DataFrame()\n",
    "        all_impl_scores = np.array([])\n",
    "        \n",
    "        for wave in range(n_waves):\n",
    "            print(f\"\\n=== Wave {wave + 1}/{n_waves} ===\")\n",
    "            \n",
    "            # Determine if we should use emulator (after first wave if enabled)\n",
    "            wave_use_emulator = use_emulator and (wave > 0) and self.emulator_trained\n",
    "            \n",
    "            # Run the wave\n",
    "            successful_samples, impl_scores = self.run_wave(\n",
    "                current_samples, \n",
    "                use_emulator=wave_use_emulator\n",
    "            )\n",
    "            \n",
    "            print(f\"Evaluated {len(successful_samples)} samples\")\n",
    "            print(f\"Min implausibility: {np.min(impl_scores):.2f}\")\n",
    "            print(f\"Max implausibility: {np.max(impl_scores):.2f}\")\n",
    "            \n",
    "            # Store results\n",
    "            all_samples = pd.concat([all_samples, successful_samples])\n",
    "            all_impl_scores = np.concatenate([all_impl_scores, impl_scores])\n",
    "            \n",
    "            # Identify Not Ruled Out Yet (NROY) points\n",
    "            nroy_mask = impl_scores <= self.history_matcher.threshold\n",
    "            nroy_samples = successful_samples[nroy_mask]\n",
    "            print(f\"NROY points: {len(nroy_samples)}\")\n",
    "            \n",
    "            # Train emulator after first wave if requested\n",
    "            if wave == 0 and use_emulator and len(successful_samples) > 10:\n",
    "                X_train = successful_samples[self.param_names].values\n",
    "                # Collect all outputs for training data\n",
    "                y_train = []\n",
    "                for _, row in successful_samples.iterrows():\n",
    "                    outputs = self.run_simulation(row.to_dict())\n",
    "                    if outputs is not None:\n",
    "                        y_train.append([outputs[signal] for signal in self.observed_data])\n",
    "                y_train = np.array(y_train)\n",
    "                self.train_emulator(X_train, y_train)\n",
    "            \n",
    "            # Generate new samples for next wave\n",
    "            if wave < n_waves - 1:\n",
    "                if len(nroy_samples) >= 2:\n",
    "                    # Sample from NROY space\n",
    "                    new_samples = self.history_matcher._sample_new_points(\n",
    "                        nroy_samples[self.param_names].values, \n",
    "                        n_samples_per_wave\n",
    "                    )\n",
    "                    current_samples = pd.DataFrame(new_samples, columns=self.param_names)\n",
    "                else:\n",
    "                    # Fall back to random sampling\n",
    "                    print(\"Not enough NROY points - using random sampling\")\n",
    "                    current_samples = self.generate_samples(n_samples_per_wave)\n",
    "        \n",
    "        return all_samples, all_impl_scores\n",
    "\n",
    "    def plot_results(self, samples: pd.DataFrame, impl_scores: np.ndarray):\n",
    "        \"\"\"Plot 2D parameter space with implausibility\"\"\"\n",
    "        if len(self.param_names) < 2:\n",
    "            return\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        sc = ax.scatter(samples[self.param_names[0]], \n",
    "                        samples[self.param_names[1]], \n",
    "                        c=impl_scores,\n",
    "                        cmap='viridis_r',\n",
    "                        vmin=0,\n",
    "                        vmax=self.history_matcher.threshold*1.5)\n",
    "        \n",
    "        ax.set_xlabel(self.param_names[0])\n",
    "        ax.set_ylabel(self.param_names[1])\n",
    "        ax.set_title(\"History Matching Results\")\n",
    "        plt.colorbar(sc, label='Implausibility')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define observed data (target values)\n",
    "    observed_signals = {\n",
    "        \"ao.P_min\": 80.0,    # Minimum aortic pressure (mmHg)\n",
    "        \"ao.P_max\": 120.0,   # Maximum aortic pressure (mmHg)\n",
    "    }\n",
    "\n",
    "    # Define parameter ranges to explore\n",
    "    param_ranges = {\n",
    "        \"lv.E_act\": (0.0, 20.0),  # LV active elastance\n",
    "        \"lv.v_ref\": (0.0, 20.0),  # LV reference volume\n",
    "        \"la.E_act\": (0.0, 10.5),  # LA active elastance\n",
    "    }\n",
    "\n",
    "    # Create history matcher instance\n",
    "    hm = NaghaviHistoryMatcher(\n",
    "        observed_data=observed_signals,\n",
    "        param_ranges=param_ranges,\n",
    "        implausibility_threshold=3.0\n",
    "    )\n",
    "\n",
    "    # Run history matching (with emulator after first wave)\n",
    "    all_samples, all_impl_scores = hm.history_matching(\n",
    "        n_waves=3,\n",
    "        n_samples_per_wave=50,\n",
    "        use_emulator=True\n",
    "    )\n",
    "\n",
    "    # Plot results\n",
    "    hm.plot_results(all_samples, all_impl_scores)\n",
    "\n",
    "    # Print best parameters\n",
    "    best_idx = np.argmin(all_impl_scores)\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(all_samples.iloc[best_idx])\n",
    "    print(f\"Implausibility: {all_impl_scores[best_idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "from autoemulate.history_matching import HistoryMatcher, BaseSimulator\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define your parameter ranges\n",
    "    param_ranges = {\n",
    "        \"lv.E_act\": (0.0, 20.0),  # LV active elastance\n",
    "        \"lv.v_ref\": (0.0, 20.0),  # LV reference volume\n",
    "        \"la.E_act\": (0.0, 10.5),  # LA active elastance\n",
    "    }\n",
    "    \n",
    "    # Define observed data with means and variances\n",
    "    observations = {\n",
    "        \"ao.P_min\": (80.0, 0.1),    # (mean, variance) for minimum aortic pressure\n",
    "        \"ao.P_max\": (120.0, 0.1),    # (mean, variance) for maximum aortic pressure\n",
    "    }\n",
    "    \n",
    "    # Create simulator instance\n",
    "    simulator = NaghaviSimulator(\n",
    "        observed_data={k: v[0] for k, v in observations.items()},  # Extract just the means\n",
    "        param_ranges=param_ranges,\n",
    "        n_cycles=40,\n",
    "        dt=0.001\n",
    "    )\n",
    "    \n",
    "    # Test generating samples\n",
    "    samples = simulator.generate_initial_samples(10)\n",
    "    print(\"Generated samples:\", samples)\n",
    "\n",
    "    # Create history matcher\n",
    "    hm = HistoryMatcher(\n",
    "        simulator=simulator,\n",
    "        observations=observations,  # This needs both means and variances\n",
    "        threshold=3.0\n",
    "    )\n",
    "\n",
    "    # Run history matching\n",
    "    all_samples, all_impl_scores = hm.run_history_matching(\n",
    "        n_waves=20,\n",
    "        n_samples_per_wave=50,\n",
    "        use_emulator=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
